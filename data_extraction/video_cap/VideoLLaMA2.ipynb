{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "!git clone https://github.com/DAMO-NLP-SG/VideoLLaMA2\n",
    "%cd VideoLLaMA2\n",
    "!pip install -r requirements.txt"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m417.9/417.9 MB\u001B[0m \u001B[31m6.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:02\u001B[0mm\r\n",
      "\u001B[?25hDownloading nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux2014_x86_64.whl (13.1 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m13.1/13.1 MB\u001B[0m \u001B[31m4.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl (23.2 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m23.2/23.2 MB\u001B[0m \u001B[31m3.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl (875 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m875.6/875.6 kB\u001B[0m \u001B[31m4.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m168.4/168.4 MB\u001B[0m \u001B[31m4.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading nvidia_curand_cu11-10.3.0.86-py3-none-manylinux2014_x86_64.whl (58.1 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m58.1/58.1 MB\u001B[0m \u001B[31m2.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux2014_x86_64.whl (128.2 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m128.2/128.2 MB\u001B[0m \u001B[31m11.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux2014_x86_64.whl (204.1 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m204.1/204.1 MB\u001B[0m \u001B[31m7.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading nvidia_nvtx_cu11-11.8.86-py3-none-manylinux2014_x86_64.whl (99 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m99.1/99.1 kB\u001B[0m \u001B[31m10.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading pysubs2-1.7.3-py3-none-any.whl (37 kB)\r\n",
      "Downloading shortuuid-1.0.13-py3-none-any.whl (10 kB)\r\n",
      "Downloading pydantic-2.8.2-py3-none-any.whl (423 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m423.9/423.9 kB\u001B[0m \u001B[31m9.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading pydantic_core-2.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.1/2.1 MB\u001B[0m \u001B[31m7.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading openai-1.41.0-py3-none-any.whl (362 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m362.4/362.4 kB\u001B[0m \u001B[31m9.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading uvicorn-0.30.6-py3-none-any.whl (62 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m62.8/62.8 kB\u001B[0m \u001B[31m11.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading fastapi-0.112.1-py3-none-any.whl (93 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m93.2/93.2 kB\u001B[0m \u001B[31m9.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading wandb-0.17.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m9.3/9.3 MB\u001B[0m \u001B[31m7.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\r\n",
      "Downloading altair-5.4.0-py3-none-any.whl (671 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m671.7/671.7 kB\u001B[0m \u001B[31m10.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\r\n",
      "Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\r\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\r\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\r\n",
      "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m207.3/207.3 kB\u001B[0m \u001B[31m11.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading httpcore-0.17.3-py3-none-any.whl (74 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m74.5/74.5 kB\u001B[0m \u001B[31m10.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading importlib_resources-6.4.2-py3-none-any.whl (34 kB)\r\n",
      "Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m318.9/318.9 kB\u001B[0m \u001B[31m8.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m141.9/141.9 kB\u001B[0m \u001B[31m8.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\r\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\r\n",
      "Downloading sentry_sdk-2.13.0-py2.py3-none-any.whl (309 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m309.1/309.1 kB\u001B[0m \u001B[31m9.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading starlette-0.38.2-py3-none-any.whl (72 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m72.0/72.0 kB\u001B[0m \u001B[31m10.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m129.9/129.9 kB\u001B[0m \u001B[31m1.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\r\n",
      "Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m54.0/54.0 kB\u001B[0m \u001B[31m6.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading latex2mathml-3.77.0-py3-none-any.whl (73 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m73.7/73.7 kB\u001B[0m \u001B[31m8.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading markdown2-2.5.0-py2.py3-none-any.whl (47 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m47.2/47.2 kB\u001B[0m \u001B[31m9.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m307.2/307.2 kB\u001B[0m \u001B[31m6.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\r\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\r\n",
      "Downloading pynvml-11.5.3-py3-none-any.whl (53 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m53.1/53.1 kB\u001B[0m \u001B[31m7.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\r\n",
      "Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\r\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m62.7/62.7 kB\u001B[0m \u001B[31m7.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading narwhals-1.4.2-py3-none-any.whl (144 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m145.0/145.0 kB\u001B[0m \u001B[31m7.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m67.1/67.1 kB\u001B[0m \u001B[31m6.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\r\n",
      "Building wheels for collected packages: deepspeed, moviepy, wavedrom\r\n",
      "  Building wheel for deepspeed (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for deepspeed: filename=deepspeed-0.13.1-py3-none-any.whl size=1350307 sha256=0349327ee1af3a1bab95cfc6333f7fc17f29e3a5d7976c3fadcb5698612adaa2\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-9wyopmvw/wheels/0f/fb/b5/b159b3500525eca167d8ca6e3a7e224b6075045cac90f47cf7\r\n",
      "  Building wheel for moviepy (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for moviepy: filename=moviepy-1.0.3-py3-none-any.whl size=110721 sha256=9bd37f1c0d8dd66bfe0119b7977891c3079a81673a479812869c52de14ff4513\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-9wyopmvw/wheels/96/32/2d/e10123bd88fbfc02fed53cc18c80a171d3c87479ed845fa7c1\r\n",
      "  Building wheel for wavedrom (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for wavedrom: filename=wavedrom-2.0.3.post3-py2.py3-none-any.whl size=30052 sha256=ae923ec62b82631f82eb3adc93e54f96f4301db96bcee266be94d30217146afa\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-9wyopmvw/wheels/9c/52/8c/38b454b42f712f325e26f633287484c7dc1ad469e1580c5954\r\n",
      "Successfully built deepspeed moviepy wavedrom\r\n",
      "Installing collected packages: sentencepiece, pydub, py-cpuinfo, ninja, hjson, websockets, uvicorn, triton, svgwrite, smmap, shortuuid, setproctitle, sentry-sdk, semantic-version, python-multipart, pysubs2, pynvml, pydantic-core, proglog, orjson, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, narwhals, markdown2, latex2mathml, jiter, importlib-resources, imageio-ffmpeg, ffmpy, einops, docker-pycreds, distro, decorator, annotated-types, aiofiles, wavedrom, starlette, scenedetect, pydantic, opencv-python, nvidia-cusolver-cu11, nvidia-cudnn-cu11, imageio, huggingface_hub, httpcore, gitdb, einops-exts, decord, torch, scikit-learn, moviepy, httpx, gitpython, fastapi, wandb, transformers, torchvision, openai, gradio_client, deepspeed, bitsandbytes, altair, accelerate, timm, peft, gradio\r\n",
      "  Attempting uninstall: sentencepiece\r\n",
      "    Found existing installation: sentencepiece 0.2.0\r\n",
      "    Uninstalling sentencepiece-0.2.0:\r\n",
      "      Successfully uninstalled sentencepiece-0.2.0\r\n",
      "  Attempting uninstall: triton\r\n",
      "    Found existing installation: triton 3.0.0\r\n",
      "    Uninstalling triton-3.0.0:\r\n",
      "      Successfully uninstalled triton-3.0.0\r\n",
      "  Attempting uninstall: numpy\r\n",
      "    Found existing installation: numpy 1.26.4\r\n",
      "    Uninstalling numpy-1.26.4:\r\n",
      "      Successfully uninstalled numpy-1.26.4\r\n",
      "  Attempting uninstall: einops\r\n",
      "    Found existing installation: einops 0.8.0\r\n",
      "    Uninstalling einops-0.8.0:\r\n",
      "      Successfully uninstalled einops-0.8.0\r\n",
      "  Attempting uninstall: decorator\r\n",
      "    Found existing installation: decorator 5.1.1\r\n",
      "    Uninstalling decorator-5.1.1:\r\n",
      "      Successfully uninstalled decorator-5.1.1\r\n",
      "  Attempting uninstall: opencv-python\r\n",
      "    Found existing installation: opencv-python 4.10.0.84\r\n",
      "    Uninstalling opencv-python-4.10.0.84:\r\n",
      "      Successfully uninstalled opencv-python-4.10.0.84\r\n",
      "  Attempting uninstall: huggingface_hub\r\n",
      "    Found existing installation: huggingface-hub 0.24.5\r\n",
      "    Uninstalling huggingface-hub-0.24.5:\r\n",
      "      Successfully uninstalled huggingface-hub-0.24.5\r\n",
      "  Attempting uninstall: httpcore\r\n",
      "    Found existing installation: httpcore 1.0.5\r\n",
      "    Uninstalling httpcore-1.0.5:\r\n",
      "      Successfully uninstalled httpcore-1.0.5\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 2.4.0\r\n",
      "    Uninstalling torch-2.4.0:\r\n",
      "      Successfully uninstalled torch-2.4.0\r\n",
      "  Attempting uninstall: scikit-learn\r\n",
      "    Found existing installation: scikit-learn 1.5.1\r\n",
      "    Uninstalling scikit-learn-1.5.1:\r\n",
      "      Successfully uninstalled scikit-learn-1.5.1\r\n",
      "  Attempting uninstall: httpx\r\n",
      "    Found existing installation: httpx 0.27.0\r\n",
      "    Uninstalling httpx-0.27.0:\r\n",
      "      Successfully uninstalled httpx-0.27.0\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.43.4\r\n",
      "    Uninstalling transformers-4.43.4:\r\n",
      "      Successfully uninstalled transformers-4.43.4\r\n",
      "  Attempting uninstall: torchvision\r\n",
      "    Found existing installation: torchvision 0.19.0\r\n",
      "    Uninstalling torchvision-0.19.0:\r\n",
      "      Successfully uninstalled torchvision-0.19.0\r\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "jupyterlab 4.2.4 requires httpx>=0.25.0, but you have httpx 0.24.1 which is incompatible.\r\n",
      "torchaudio 2.4.0 requires torch==2.4.0, but you have torch 2.2.0+cu118 which is incompatible.\u001B[0m\u001B[31m\r\n",
      "\u001B[0mSuccessfully installed accelerate-0.26.1 aiofiles-23.2.1 altair-5.4.0 annotated-types-0.7.0 bitsandbytes-0.43.0 decorator-4.4.2 decord-0.6.0 deepspeed-0.13.1 distro-1.9.0 docker-pycreds-0.4.0 einops-0.6.1 einops-exts-0.0.4 fastapi-0.112.1 ffmpy-0.4.0 gitdb-4.0.11 gitpython-3.1.43 gradio-3.50.0 gradio_client-0.6.1 hjson-3.1.0 httpcore-0.17.3 httpx-0.24.1 huggingface_hub-0.23.4 imageio-2.34.0 imageio-ffmpeg-0.4.9 importlib-resources-6.4.2 jiter-0.5.0 latex2mathml-3.77.0 markdown2-2.5.0 moviepy-1.0.3 narwhals-1.4.2 ninja-1.11.1.1 numpy-1.24.4 nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-8.7.0.84 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.19.3 nvidia-nvtx-cu11-11.8.86 openai-1.41.0 opencv-python-4.6.0.66 orjson-3.10.7 peft-0.4.0 proglog-0.1.10 py-cpuinfo-9.0.0 pydantic-2.8.2 pydantic-core-2.20.1 pydub-0.25.1 pynvml-11.5.3 pysubs2-1.7.3 python-multipart-0.0.9 scenedetect-0.6.3 scikit-learn-1.2.2 semantic-version-2.10.0 sentencepiece-0.1.99 sentry-sdk-2.13.0 setproctitle-1.3.3 shortuuid-1.0.13 smmap-5.0.1 starlette-0.38.2 svgwrite-1.4.3 timm-1.0.3 torch-2.2.0+cu118 torchvision-0.17.0+cu118 transformers-4.42.3 triton-2.2.0 uvicorn-0.30.6 wandb-0.17.7 wavedrom-2.0.3.post3 websockets-11.0.3\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\r\n",
      "Collecting flash-attn==2.5.8\r\n",
      "  Downloading flash_attn-2.5.8.tar.gz (2.5 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.5/2.5 MB\u001B[0m \u001B[31m2.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25lerror\r\n",
      "  \u001B[1;31merror\u001B[0m: \u001B[1msubprocess-exited-with-error\u001B[0m\r\n",
      "  \r\n",
      "  \u001B[31m×\u001B[0m \u001B[32mpython setup.py egg_info\u001B[0m did not run successfully.\r\n",
      "  \u001B[31m│\u001B[0m exit code: \u001B[1;36m1\u001B[0m\r\n",
      "  \u001B[31m╰─>\u001B[0m \u001B[31m[12 lines of output]\u001B[0m\r\n",
      "  \u001B[31m   \u001B[0m fatal: not a git repository (or any of the parent directories): .git\r\n",
      "  \u001B[31m   \u001B[0m Traceback (most recent call last):\r\n",
      "  \u001B[31m   \u001B[0m   File \"<string>\", line 2, in <module>\r\n",
      "  \u001B[31m   \u001B[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\r\n",
      "  \u001B[31m   \u001B[0m   File \"/tmp/pip-install-_3n34gsg/flash-attn_2026352c443a4d62bd6a8b692b630d3b/setup.py\", line 115, in <module>\r\n",
      "  \u001B[31m   \u001B[0m     raise RuntimeError(\r\n",
      "  \u001B[31m   \u001B[0m RuntimeError: FlashAttention is only supported on CUDA 11.6 and above.  Note: make sure nvcc has a supported version by running nvcc -V.\r\n",
      "  \u001B[31m   \u001B[0m \r\n",
      "  \u001B[31m   \u001B[0m \r\n",
      "  \u001B[31m   \u001B[0m torch.__version__  = 2.2.0+cu118\r\n",
      "  \u001B[31m   \u001B[0m \r\n",
      "  \u001B[31m   \u001B[0m \r\n",
      "  \u001B[31m   \u001B[0m \u001B[31m[end of output]\u001B[0m\r\n",
      "  \r\n",
      "  \u001B[1;35mnote\u001B[0m: This error originates from a subprocess, and is likely not a problem with pip.\r\n",
      "\u001B[1;31merror\u001B[0m: \u001B[1mmetadata-generation-failed\u001B[0m\r\n",
      "\r\n",
      "\u001B[31m×\u001B[0m Encountered error while generating package metadata.\r\n",
      "\u001B[31m╰─>\u001B[0m See above for output.\r\n",
      "\r\n",
      "\u001B[1;35mnote\u001B[0m: This is an issue with the package mentioned above, not pip.\r\n",
      "\u001B[1;36mhint\u001B[0m: See above for details.\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "\u001B[?25h"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "!pip install flash-attn --no-build-isolation\n",
    "!pip install moviepy"
   ],
   "id": "71c55f19c13248ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T03:42:53.358798Z",
     "start_time": "2024-08-17T03:42:53.356425Z"
    }
   },
   "cell_type": "code",
   "source": "%cd VideoLLaMA2",
   "id": "6093deaae681b2d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/daoan/Projects/AI_Challenge_HCMC_2024/data_extraction/video_cap/VideoLLaMA2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T03:43:09.266120Z",
     "start_time": "2024-08-17T03:43:05.675196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "sys.path.append('./')\n",
    "from videollama2.utils import disable_torch_init\n",
    "from videollama2 import model_init, mm_infer\n",
    "import os\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip"
   ],
   "id": "62709ba1b789d72f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-17 10:43:07.406097: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-17 10:43:07.586454: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-17 10:43:07.656652: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-17 10:43:07.677633: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-17 10:43:07.819382: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-17 10:43:08.397427: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T04:28:28.590870Z",
     "start_time": "2024-08-17T03:43:19.797398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "disable_torch_init()\n",
    "modal = 'video'\n",
    "model_path = 'DAMO-NLP-SG/VideoLLaMA2-7B'\n",
    "model, processor, tokenizer = model_init(model_path)"
   ],
   "id": "b1f3b31004c29062",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/1.16k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "95972a3f6e7b4943a31dd28f9949f09e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.08k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7fe7dc69d4344a658852462e6b50819d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "de29ce6f9f014ecaa1f924cc520a4351"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6dbd0f8b8aa0441ea1e538ae1e154b66"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e3f24e8291da4f5c8c169cbf623f99d6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/82.2k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ef5aacbc440d46a1abaec9c96b2ebc2a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "75bb52b405f447d580065d5d4a28d1db"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0132f8909a9c44249dad6ea897ee10d6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "97ed7894eef846778aa522afb2571ef3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4590f2b681604049bee09b16c7f444e9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.14G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d34edb3dcefe41ff84ed7517b6cb2699"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/4.76k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "92099287a6d645aeb83cf25ee19272e4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "898b9cb50ac64bacaadb558ea86de31a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DAMO-NLP-SG/VideoLLaMA2-7B were not used when initializing Videollama2MistralForCausalLM: ['model.vision_tower.vision_tower.vision_model.embeddings.class_embedding', 'model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight', 'model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.post_layernorm.bias', 'model.vision_tower.vision_tower.vision_model.post_layernorm.weight', 'model.vision_tower.vision_tower.vision_model.pre_layrnorm.bias', 'model.vision_tower.vision_tower.vision_model.pre_layrnorm.weight']\n",
      "- This IS expected if you are initializing Videollama2MistralForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Videollama2MistralForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f75661b2cffd4c838e67a6b26ed7383a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "acca74a5433d43b8b1fb4e1a4f81195c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.71G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c5227f2b8aeb4101a4b04ef27abeb4bc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "b8411765948dc35e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T14:42:00.123945Z",
     "start_time": "2024-08-17T14:42:00.121614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cut_video(input_file, output_file, start_frame, end_frame):\n",
    "    clip = VideoFileClip(input_file)\n",
    "    fps = clip.fps\n",
    "    start_time = start_frame / fps\n",
    "    end_time = end_frame / fps\n",
    "    cut_clip = clip.subclip(start_time, end_time)\n",
    "    cut_clip.write_videofile(output_file, codec='libx264', verbose=False, logger=None)"
   ],
   "id": "adb6605083808c61",
   "outputs": [],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T14:42:00.290686Z",
     "start_time": "2024-08-17T14:42:00.287131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_all_scene_files(root_dir, extensions=[\".json\"]):\n",
    "    scene_files = []\n",
    "    for dirpath, _, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            if any(filename.lower().endswith(ext) for ext in extensions):\n",
    "                scene_files.append(os.path.join(dirpath, filename))\n",
    "    return scene_files"
   ],
   "id": "aeacd7dd3cecde7f",
   "outputs": [],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T14:42:00.450070Z",
     "start_time": "2024-08-17T14:42:00.447694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_video_by_scene_file(scene_file, video_dir):\n",
    "    folder_L_video = scene_file.split('/')[-2]\n",
    "    file_V_video = scene_file.split('/')[-1].replace('.json', '.mp4')\n",
    "    video_name = folder_L_video + \"_\" + file_V_video\n",
    "    video_path = os.path.join(video_dir, \"Videos_\" + folder_L_video, \"video\", video_name)\n",
    "    return video_path"
   ],
   "id": "7602874e46707e35",
   "outputs": [],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T14:42:00.644201Z",
     "start_time": "2024-08-17T14:42:00.642184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_all_folders_if_not_exists(path):\n",
    "    os.makedirs(path, exist_ok=True)"
   ],
   "id": "ccc94ab1c9d4dd0d",
   "outputs": [],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T14:42:01.006508Z",
     "start_time": "2024-08-17T14:42:01.003384Z"
    }
   },
   "cell_type": "code",
   "source": "scene_files = find_all_scene_files('/home/daoan/Projects/AI_Challenge_HCMC_2024/data_extraction/video_cap/SceneJSON')",
   "id": "c7ff7884c611b1d",
   "outputs": [],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-17T14:42:01.269899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "modal = 'video'\n",
    "instruct = 'describe the video?'\n",
    "cut_output_file = \"cut_output.mp4\"\n",
    "\n",
    "\n",
    "for scene_file in tqdm(scene_files, desc=\"Processing scene files\"):\n",
    "    with open(scene_file, 'r') as f:\n",
    "        scene_data = json.load(f)\n",
    "        video_file = find_video_by_scene_file(scene_file, '/media/daoan/T7 Shield2/VN_Multi_User_Video_Search/videos')\n",
    "        description_file = scene_file.replace('SceneJSON', 'Description')\n",
    "        create_all_folders_if_not_exists(os.path.dirname(description_file))\n",
    "        if os.path.exists(description_file):\n",
    "            continue\n",
    "        description_list = []\n",
    "        for i in tqdm(range(len(scene_data)), desc=\"Processing scenes\"):\n",
    "                start_frame = scene_data[i][0]\n",
    "                end_frame = scene_data[i][1]\n",
    "                try:\n",
    "                    cut_video(video_file, cut_output_file, start_frame, end_frame)\n",
    "                except  Exception as e:\n",
    "                    print(f\"Error: {e}\")\n",
    "                    continue    \n",
    "                description = mm_infer(processor[modal](cut_output_file), instruct, model=model, tokenizer=tokenizer, do_sample=False, modal=modal)\n",
    "                os.remove(cut_output_file)\n",
    "                description_list.append([start_frame, end_frame, description])\n",
    "        with open(description_file, 'w') as f:\n",
    "            json.dump(description_list, f)           "
   ],
   "id": "8fcad264a59c9d1c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing scene files:   0%|          | 0/1210 [00:00<?, ?it/s]\n",
      "Processing scenes:   0%|          | 0/408 [00:00<?, ?it/s]\u001B[A\n",
      "Processing scenes:   0%|          | 1/408 [00:49<5:38:50, 49.95s/it]\u001B[A\n",
      "Processing scenes:   0%|          | 2/408 [00:52<2:29:23, 22.08s/it]\u001B[A\n",
      "Processing scenes:   1%|          | 3/408 [00:55<1:30:45, 13.45s/it]\u001B[A\n",
      "Processing scenes:   1%|          | 4/408 [00:57<59:36,  8.85s/it]  \u001B[A\n",
      "Processing scenes:   1%|          | 5/408 [00:59<42:09,  6.28s/it]\u001B[A\n",
      "Processing scenes:   1%|▏         | 6/408 [01:03<36:44,  5.48s/it]\u001B[A\n",
      "Processing scenes:   2%|▏         | 7/408 [01:05<29:32,  4.42s/it]\u001B[A\n",
      "Processing scenes:   2%|▏         | 8/408 [01:09<28:01,  4.20s/it]\u001B[A\n",
      "Processing scenes:   2%|▏         | 9/408 [01:13<27:39,  4.16s/it]\u001B[A\n",
      "Processing scenes:   2%|▏         | 10/408 [01:16<26:19,  3.97s/it]\u001B[A\n",
      "Processing scenes:   3%|▎         | 11/408 [01:19<23:15,  3.51s/it]\u001B[A\n",
      "Processing scenes:   3%|▎         | 12/408 [01:21<19:58,  3.03s/it]\u001B[A\n",
      "Processing scenes:   3%|▎         | 13/408 [01:22<17:20,  2.63s/it]\u001B[A\n",
      "Processing scenes:   3%|▎         | 14/408 [01:26<18:20,  2.79s/it]\u001B[A\n",
      "Processing scenes:   4%|▎         | 15/408 [01:29<19:57,  3.05s/it]\u001B[A\n",
      "Processing scenes:   4%|▍         | 16/408 [01:33<20:44,  3.17s/it]\u001B[A\n",
      "Processing scenes:   4%|▍         | 17/408 [01:35<18:36,  2.86s/it]\u001B[A\n",
      "Processing scenes:   4%|▍         | 18/408 [01:37<16:43,  2.57s/it]\u001B[A\n",
      "Processing scenes:   5%|▍         | 19/408 [01:39<15:33,  2.40s/it]\u001B[A\n",
      "Processing scenes:   5%|▍         | 20/408 [01:42<17:39,  2.73s/it]\u001B[A\n",
      "Processing scenes:   5%|▌         | 21/408 [01:46<20:39,  3.20s/it]\u001B[A\n",
      "Processing scenes:   5%|▌         | 22/408 [01:48<18:06,  2.81s/it]\u001B[A\n",
      "Processing scenes:   6%|▌         | 23/408 [01:52<19:56,  3.11s/it]\u001B[A\n",
      "Processing scenes:   6%|▌         | 24/408 [01:54<16:40,  2.61s/it]\u001B[A\n",
      "Processing scenes:   6%|▌         | 25/408 [01:55<14:50,  2.33s/it]\u001B[A\n",
      "Processing scenes:   6%|▋         | 26/408 [01:57<14:33,  2.29s/it]\u001B[A\n",
      "Processing scenes:   7%|▋         | 27/408 [02:00<14:50,  2.34s/it]\u001B[A\n",
      "Processing scenes:   7%|▋         | 28/408 [02:02<13:30,  2.13s/it]\u001B[A\n",
      "Processing scenes:   7%|▋         | 29/408 [02:05<16:48,  2.66s/it]\u001B[A\n",
      "Processing scenes:   7%|▋         | 30/408 [02:07<14:11,  2.25s/it]\u001B[A\n",
      "Processing scenes:   8%|▊         | 31/408 [02:09<14:29,  2.31s/it]\u001B[A\n",
      "Processing scenes:   8%|▊         | 32/408 [02:13<17:33,  2.80s/it]\u001B[A\n",
      "Processing scenes:   8%|▊         | 33/408 [02:17<18:53,  3.02s/it]\u001B[A\n",
      "Processing scenes:   8%|▊         | 34/408 [02:18<15:53,  2.55s/it]\u001B[A\n",
      "Processing scenes:   9%|▊         | 35/408 [02:21<15:58,  2.57s/it]\u001B[A\n",
      "Processing scenes:   9%|▉         | 36/408 [02:25<18:19,  2.96s/it]\u001B[A\n",
      "Processing scenes:   9%|▉         | 37/408 [02:27<18:05,  2.92s/it]\u001B[A\n",
      "Processing scenes:   9%|▉         | 38/408 [02:31<18:41,  3.03s/it]\u001B[A\n",
      "Processing scenes:  10%|▉         | 39/408 [02:36<22:28,  3.65s/it]\u001B[A\n",
      "Processing scenes:  10%|▉         | 40/408 [02:39<20:34,  3.36s/it]\u001B[A\n",
      "Processing scenes:  10%|█         | 41/408 [02:43<22:10,  3.63s/it]\u001B[A\n",
      "Processing scenes:  10%|█         | 42/408 [02:46<21:42,  3.56s/it]\u001B[A\n",
      "Processing scenes:  11%|█         | 43/408 [02:48<18:34,  3.05s/it]\u001B[A\n",
      "Processing scenes:  11%|█         | 44/408 [02:51<19:07,  3.15s/it]\u001B[A\n",
      "Processing scenes:  11%|█         | 45/408 [02:53<16:51,  2.79s/it]\u001B[A\n",
      "Processing scenes:  11%|█▏        | 46/408 [02:56<17:14,  2.86s/it]\u001B[A\n",
      "Processing scenes:  12%|█▏        | 47/408 [02:58<15:36,  2.59s/it]\u001B[A\n",
      "Processing scenes:  12%|█▏        | 48/408 [03:01<15:16,  2.55s/it]\u001B[A\n",
      "Processing scenes:  12%|█▏        | 49/408 [03:04<17:04,  2.85s/it]\u001B[A\n",
      "Processing scenes:  12%|█▏        | 50/408 [03:08<18:33,  3.11s/it]\u001B[A\n",
      "Processing scenes:  12%|█▎        | 51/408 [03:10<16:30,  2.78s/it]\u001B[A\n",
      "Processing scenes:  13%|█▎        | 52/408 [03:13<16:11,  2.73s/it]\u001B[A\n",
      "Processing scenes:  13%|█▎        | 53/408 [03:15<15:42,  2.65s/it]\u001B[A\n",
      "Processing scenes:  13%|█▎        | 54/408 [03:19<18:09,  3.08s/it]\u001B[A\n",
      "Processing scenes:  13%|█▎        | 55/408 [03:20<14:37,  2.49s/it]\u001B[A\n",
      "Processing scenes:  14%|█▎        | 56/408 [03:22<13:21,  2.28s/it]\u001B[A\n",
      "Processing scenes:  14%|█▍        | 57/408 [03:24<12:45,  2.18s/it]\u001B[A\n",
      "Processing scenes:  14%|█▍        | 58/408 [03:27<14:32,  2.49s/it]\u001B[A\n",
      "Processing scenes:  14%|█▍        | 59/408 [03:31<16:19,  2.81s/it]\u001B[A\n",
      "Processing scenes:  15%|█▍        | 60/408 [03:32<14:08,  2.44s/it]\u001B[A\n",
      "Processing scenes:  15%|█▍        | 61/408 [03:37<17:54,  3.10s/it]\u001B[A\n",
      "Processing scenes:  15%|█▌        | 62/408 [03:39<15:14,  2.64s/it]\u001B[A\n",
      "Processing scenes:  15%|█▌        | 63/408 [03:42<16:37,  2.89s/it]\u001B[A\n",
      "Processing scenes:  16%|█▌        | 64/408 [03:44<15:23,  2.69s/it]\u001B[A\n",
      "Processing scenes:  16%|█▌        | 65/408 [03:46<13:41,  2.40s/it]\u001B[A\n",
      "Processing scenes:  16%|█▌        | 66/408 [03:48<12:29,  2.19s/it]\u001B[A\n",
      "Processing scenes:  16%|█▋        | 67/408 [03:52<16:36,  2.92s/it]\u001B[A\n",
      "Processing scenes:  17%|█▋        | 68/408 [03:55<16:25,  2.90s/it]\u001B[A\n",
      "Processing scenes:  17%|█▋        | 69/408 [04:00<19:25,  3.44s/it]\u001B[A\n",
      "Processing scenes:  17%|█▋        | 70/408 [04:02<17:11,  3.05s/it]\u001B[A\n",
      "Processing scenes:  17%|█▋        | 71/408 [04:04<14:35,  2.60s/it]\u001B[A\n",
      "Processing scenes:  18%|█▊        | 72/408 [04:06<13:35,  2.43s/it]\u001B[A\n",
      "Processing scenes:  18%|█▊        | 73/408 [04:10<17:36,  3.15s/it]\u001B[A\n",
      "Processing scenes:  18%|█▊        | 74/408 [04:13<16:17,  2.93s/it]\u001B[A\n",
      "Processing scenes:  18%|█▊        | 75/408 [04:17<18:10,  3.28s/it]\u001B[A\n",
      "Processing scenes:  19%|█▊        | 76/408 [04:20<17:32,  3.17s/it]\u001B[A\n",
      "Processing scenes:  19%|█▉        | 77/408 [04:22<15:40,  2.84s/it]\u001B[A\n",
      "Processing scenes:  19%|█▉        | 78/408 [04:26<17:56,  3.26s/it]\u001B[A\n",
      "Processing scenes:  19%|█▉        | 79/408 [04:29<16:26,  3.00s/it]\u001B[A\n",
      "Processing scenes:  20%|█▉        | 80/408 [04:32<16:26,  3.01s/it]\u001B[A\n",
      "Processing scenes:  20%|█▉        | 81/408 [04:36<18:12,  3.34s/it]\u001B[A\n",
      "Processing scenes:  20%|██        | 82/408 [04:39<18:21,  3.38s/it]\u001B[A\n",
      "Processing scenes:  20%|██        | 83/408 [04:39<13:02,  2.41s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: [Errno 32] Broken pipe\n",
      "\n",
      "MoviePy error: FFMPEG encountered the following error while writing file cut_output.mp4:\n",
      "\n",
      " b'cut_outputTEMP_MPY_wvf_snd.mp3: Invalid data found when processing input\\n'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes:  21%|██        | 84/408 [04:43<15:17,  2.83s/it]\u001B[A\n",
      "Processing scenes:  21%|██        | 85/408 [04:49<19:16,  3.58s/it]\u001B[A\n",
      "Processing scenes:  21%|██        | 86/408 [04:53<20:10,  3.76s/it]\u001B[A\n",
      "Processing scenes:  21%|██▏       | 87/408 [04:54<16:51,  3.15s/it]\u001B[A\n",
      "Processing scenes:  22%|██▏       | 88/408 [04:59<18:46,  3.52s/it]\u001B[A\n",
      "Processing scenes:  22%|██▏       | 89/408 [05:02<18:32,  3.49s/it]\u001B[A\n",
      "Processing scenes:  22%|██▏       | 90/408 [05:04<15:33,  2.94s/it]\u001B[A\n",
      "Processing scenes:  22%|██▏       | 91/408 [05:07<16:31,  3.13s/it]\u001B[A\n",
      "Processing scenes:  23%|██▎       | 92/408 [05:10<14:50,  2.82s/it]\u001B[A\n",
      "Processing scenes:  23%|██▎       | 93/408 [05:11<12:31,  2.38s/it]\u001B[A\n",
      "Processing scenes:  23%|██▎       | 94/408 [05:13<12:29,  2.39s/it]\u001B[A\n",
      "Processing scenes:  23%|██▎       | 95/408 [05:16<12:31,  2.40s/it]\u001B[A\n",
      "Processing scenes:  24%|██▎       | 96/408 [05:21<17:11,  3.31s/it]\u001B[A\n",
      "Processing scenes:  24%|██▍       | 97/408 [05:25<18:35,  3.59s/it]\u001B[A\n",
      "Processing scenes:  24%|██▍       | 98/408 [05:27<16:05,  3.11s/it]\u001B[A\n",
      "Processing scenes:  24%|██▍       | 99/408 [05:29<13:15,  2.57s/it]\u001B[A\n",
      "Processing scenes:  25%|██▍       | 100/408 [05:33<15:40,  3.05s/it]\u001B[A\n",
      "Processing scenes:  25%|██▍       | 101/408 [05:35<13:34,  2.65s/it]\u001B[A\n",
      "Processing scenes:  25%|██▌       | 102/408 [05:36<12:13,  2.40s/it]\u001B[A\n",
      "Processing scenes:  25%|██▌       | 103/408 [05:39<12:33,  2.47s/it]\u001B[A\n",
      "Processing scenes:  25%|██▌       | 104/408 [05:41<11:46,  2.32s/it]\u001B[A\n",
      "Processing scenes:  26%|██▌       | 105/408 [06:31<1:23:32, 16.54s/it]\u001B[A\n",
      "Processing scenes:  26%|██▌       | 106/408 [06:33<1:01:46, 12.27s/it]\u001B[A\n",
      "Processing scenes:  26%|██▌       | 107/408 [06:36<47:23,  9.45s/it]  \u001B[A\n",
      "Processing scenes:  26%|██▋       | 108/408 [06:40<39:09,  7.83s/it]\u001B[A\n",
      "Processing scenes:  27%|██▋       | 109/408 [06:42<29:51,  5.99s/it]\u001B[A\n",
      "Processing scenes:  27%|██▋       | 110/408 [06:43<23:20,  4.70s/it]\u001B[A\n",
      "Processing scenes:  27%|██▋       | 111/408 [06:45<19:02,  3.85s/it]\u001B[A\n",
      "Processing scenes:  27%|██▋       | 112/408 [06:47<15:18,  3.10s/it]\u001B[A\n",
      "Processing scenes:  28%|██▊       | 113/408 [06:50<15:51,  3.22s/it]\u001B[A\n",
      "Processing scenes:  28%|██▊       | 114/408 [06:52<13:31,  2.76s/it]\u001B[A\n",
      "Processing scenes:  28%|██▊       | 115/408 [06:54<11:58,  2.45s/it]\u001B[A\n",
      "Processing scenes:  28%|██▊       | 116/408 [06:57<12:53,  2.65s/it]\u001B[A\n",
      "Processing scenes:  29%|██▊       | 117/408 [06:58<11:42,  2.42s/it]\u001B[A\n",
      "Processing scenes:  29%|██▉       | 118/408 [07:00<11:03,  2.29s/it]\u001B[A\n",
      "Processing scenes:  29%|██▉       | 119/408 [07:03<11:29,  2.39s/it]\u001B[A\n",
      "Processing scenes:  29%|██▉       | 120/408 [07:06<12:14,  2.55s/it]\u001B[A\n",
      "Processing scenes:  30%|██▉       | 121/408 [07:10<13:53,  2.90s/it]\u001B[A\n",
      "Processing scenes:  30%|██▉       | 122/408 [07:12<12:50,  2.69s/it]\u001B[A\n",
      "Processing scenes:  30%|███       | 123/408 [07:15<13:48,  2.91s/it]\u001B[A\n",
      "Processing scenes:  30%|███       | 124/408 [07:20<15:49,  3.34s/it]\u001B[A\n",
      "Processing scenes:  31%|███       | 125/408 [07:24<16:48,  3.57s/it]\u001B[A\n",
      "Processing scenes:  31%|███       | 126/408 [07:27<15:51,  3.38s/it]\u001B[A\n",
      "Processing scenes:  31%|███       | 127/408 [07:29<13:53,  2.97s/it]\u001B[A\n",
      "Processing scenes:  31%|███▏      | 128/408 [07:31<12:54,  2.77s/it]\u001B[A\n",
      "Processing scenes:  32%|███▏      | 129/408 [07:36<15:44,  3.38s/it]\u001B[A\n",
      "Processing scenes:  32%|███▏      | 130/408 [07:39<15:04,  3.25s/it]\u001B[A\n",
      "Processing scenes:  32%|███▏      | 131/408 [07:41<12:54,  2.80s/it]\u001B[A\n",
      "Processing scenes:  32%|███▏      | 132/408 [07:43<12:12,  2.65s/it]\u001B[A\n",
      "Processing scenes:  33%|███▎      | 133/408 [07:45<11:22,  2.48s/it]\u001B[A\n",
      "Processing scenes:  33%|███▎      | 134/408 [07:48<11:29,  2.52s/it]\u001B[A\n",
      "Processing scenes:  33%|███▎      | 135/408 [07:49<10:17,  2.26s/it]\u001B[A\n",
      "Processing scenes:  33%|███▎      | 136/408 [07:51<10:00,  2.21s/it]\u001B[A\n",
      "Processing scenes:  34%|███▎      | 137/408 [07:54<11:07,  2.46s/it]\u001B[A\n",
      "Processing scenes:  34%|███▍      | 138/408 [07:56<09:49,  2.18s/it]\u001B[A\n",
      "Processing scenes:  34%|███▍      | 139/408 [07:59<10:56,  2.44s/it]\u001B[A\n",
      "Processing scenes:  34%|███▍      | 140/408 [08:01<10:05,  2.26s/it]\u001B[A\n",
      "Processing scenes:  35%|███▍      | 141/408 [08:03<09:31,  2.14s/it]\u001B[A\n",
      "Processing scenes:  35%|███▍      | 142/408 [08:05<09:12,  2.08s/it]\u001B[A\n",
      "Processing scenes:  35%|███▌      | 143/408 [08:06<08:21,  1.89s/it]\u001B[A\n",
      "Processing scenes:  35%|███▌      | 144/408 [08:08<08:59,  2.04s/it]\u001B[A\n",
      "Processing scenes:  36%|███▌      | 145/408 [08:10<08:10,  1.87s/it]\u001B[A\n",
      "Processing scenes:  36%|███▌      | 146/408 [08:14<10:31,  2.41s/it]\u001B[A\n",
      "Processing scenes:  36%|███▌      | 147/408 [08:16<10:28,  2.41s/it]\u001B[A\n",
      "Processing scenes:  36%|███▋      | 148/408 [08:19<11:54,  2.75s/it]\u001B[A\n",
      "Processing scenes:  37%|███▋      | 149/408 [08:24<14:06,  3.27s/it]\u001B[A\n",
      "Processing scenes:  37%|███▋      | 150/408 [08:26<12:41,  2.95s/it]\u001B[A\n",
      "Processing scenes:  37%|███▋      | 151/408 [08:29<12:24,  2.90s/it]\u001B[A\n",
      "Processing scenes:  37%|███▋      | 152/408 [08:30<10:20,  2.42s/it]\u001B[A\n",
      "Processing scenes:  38%|███▊      | 153/408 [08:35<13:22,  3.15s/it]\u001B[A\n",
      "Processing scenes:  38%|███▊      | 154/408 [08:38<12:40,  2.99s/it]\u001B[A\n",
      "Processing scenes:  38%|███▊      | 155/408 [08:39<10:49,  2.57s/it]\u001B[A\n",
      "Processing scenes:  38%|███▊      | 156/408 [08:41<09:44,  2.32s/it]\u001B[A\n",
      "Processing scenes:  38%|███▊      | 157/408 [08:44<10:21,  2.47s/it]\u001B[A\n",
      "Processing scenes:  39%|███▊      | 158/408 [08:46<09:34,  2.30s/it]\u001B[A\n",
      "Processing scenes:  39%|███▉      | 159/408 [08:50<11:45,  2.83s/it]\u001B[A\n",
      "Processing scenes:  39%|███▉      | 160/408 [08:54<13:10,  3.19s/it]\u001B[A\n",
      "Processing scenes:  39%|███▉      | 161/408 [08:56<11:40,  2.84s/it]\u001B[A\n",
      "Processing scenes:  40%|███▉      | 162/408 [08:58<10:35,  2.58s/it]\u001B[A\n",
      "Processing scenes:  40%|███▉      | 163/408 [09:04<14:32,  3.56s/it]\u001B[A\n",
      "Processing scenes:  40%|████      | 164/408 [09:06<12:28,  3.07s/it]\u001B[A\n",
      "Processing scenes:  40%|████      | 165/408 [09:09<12:12,  3.02s/it]\u001B[A\n",
      "Processing scenes:  41%|████      | 166/408 [09:12<12:54,  3.20s/it]\u001B[A\n",
      "Processing scenes:  41%|████      | 167/408 [09:17<14:29,  3.61s/it]\u001B[A\n",
      "Processing scenes:  41%|████      | 168/408 [09:20<14:04,  3.52s/it]\u001B[A\n",
      "Processing scenes:  41%|████▏     | 169/408 [09:22<11:51,  2.98s/it]\u001B[A\n",
      "Processing scenes:  42%|████▏     | 170/408 [09:24<10:53,  2.75s/it]\u001B[A\n",
      "Processing scenes:  42%|████▏     | 171/408 [09:26<09:31,  2.41s/it]\u001B[A\n",
      "Processing scenes:  42%|████▏     | 172/408 [09:28<08:55,  2.27s/it]\u001B[A\n",
      "Processing scenes:  42%|████▏     | 173/408 [09:31<10:32,  2.69s/it]\u001B[A\n",
      "Processing scenes:  43%|████▎     | 174/408 [09:33<09:23,  2.41s/it]\u001B[A\n",
      "Processing scenes:  43%|████▎     | 175/408 [09:37<11:26,  2.95s/it]\u001B[A\n",
      "Processing scenes:  43%|████▎     | 176/408 [09:39<10:16,  2.66s/it]\u001B[A\n",
      "Processing scenes:  43%|████▎     | 177/408 [09:43<11:41,  3.04s/it]\u001B[A\n",
      "Processing scenes:  44%|████▎     | 178/408 [09:45<10:41,  2.79s/it]\u001B[A\n",
      "Processing scenes:  44%|████▍     | 179/408 [09:49<11:40,  3.06s/it]\u001B[A\n",
      "Processing scenes:  44%|████▍     | 180/408 [09:51<10:52,  2.86s/it]\u001B[A\n",
      "Processing scenes:  44%|████▍     | 181/408 [09:54<10:13,  2.70s/it]\u001B[A\n",
      "Processing scenes:  45%|████▍     | 182/408 [09:58<11:43,  3.11s/it]\u001B[A\n",
      "Processing scenes:  45%|████▍     | 183/408 [10:02<12:58,  3.46s/it]\u001B[A\n",
      "Processing scenes:  45%|████▌     | 184/408 [10:05<11:51,  3.18s/it]\u001B[A\n",
      "Processing scenes:  45%|████▌     | 185/408 [10:08<12:12,  3.28s/it]\u001B[A\n",
      "Processing scenes:  46%|████▌     | 186/408 [10:10<10:26,  2.82s/it]\u001B[A\n",
      "Processing scenes:  46%|████▌     | 187/408 [10:13<10:45,  2.92s/it]\u001B[A\n",
      "Processing scenes:  46%|████▌     | 188/408 [10:17<11:45,  3.21s/it]\u001B[A\n",
      "Processing scenes:  46%|████▋     | 189/408 [10:21<12:32,  3.44s/it]\u001B[A\n",
      "Processing scenes:  47%|████▋     | 190/408 [10:25<13:26,  3.70s/it]\u001B[A\n",
      "Processing scenes:  47%|████▋     | 191/408 [10:30<14:21,  3.97s/it]\u001B[A\n",
      "Processing scenes:  47%|████▋     | 192/408 [10:32<12:27,  3.46s/it]\u001B[A\n",
      "Processing scenes:  47%|████▋     | 193/408 [10:35<12:20,  3.45s/it]\u001B[A\n",
      "Processing scenes:  48%|████▊     | 194/408 [10:40<13:47,  3.87s/it]\u001B[A\n",
      "Processing scenes:  48%|████▊     | 195/408 [10:43<13:00,  3.66s/it]\u001B[A\n",
      "Processing scenes:  48%|████▊     | 196/408 [10:46<11:48,  3.34s/it]\u001B[A\n",
      "Processing scenes:  48%|████▊     | 197/408 [10:48<10:38,  3.02s/it]\u001B[A\n",
      "Processing scenes:  49%|████▊     | 198/408 [11:09<29:19,  8.38s/it]\u001B[A\n",
      "Processing scenes:  49%|████▉     | 199/408 [11:11<22:44,  6.53s/it]\u001B[A\n",
      "Processing scenes:  49%|████▉     | 200/408 [11:14<18:03,  5.21s/it]\u001B[A\n",
      "Processing scenes:  49%|████▉     | 201/408 [11:15<14:21,  4.16s/it]\u001B[A\n",
      "Processing scenes:  50%|████▉     | 202/408 [11:17<11:41,  3.40s/it]\u001B[A\n",
      "Processing scenes:  50%|████▉     | 203/408 [11:19<10:09,  2.97s/it]\u001B[A\n",
      "Processing scenes:  50%|█████     | 204/408 [11:24<12:20,  3.63s/it]\u001B[A\n",
      "Processing scenes:  50%|█████     | 205/408 [11:28<12:10,  3.60s/it]\u001B[A\n",
      "Processing scenes:  50%|█████     | 206/408 [11:30<10:28,  3.11s/it]\u001B[A\n",
      "Processing scenes:  51%|█████     | 207/408 [11:31<08:36,  2.57s/it]\u001B[A\n",
      "Processing scenes:  51%|█████     | 208/408 [11:32<07:23,  2.22s/it]\u001B[A\n",
      "Processing scenes:  51%|█████     | 209/408 [11:34<06:29,  1.96s/it]\u001B[A\n",
      "Processing scenes:  51%|█████▏    | 210/408 [11:35<05:57,  1.81s/it]\u001B[A\n",
      "Processing scenes:  52%|█████▏    | 211/408 [11:36<05:32,  1.69s/it]\u001B[A\n",
      "Processing scenes:  52%|█████▏    | 212/408 [11:39<06:03,  1.85s/it]\u001B[A\n",
      "Processing scenes:  52%|█████▏    | 213/408 [11:42<07:07,  2.19s/it]\u001B[A\n",
      "Processing scenes:  52%|█████▏    | 214/408 [11:43<06:28,  2.00s/it]\u001B[A\n",
      "Processing scenes:  53%|█████▎    | 215/408 [11:45<06:09,  1.92s/it]\u001B[A\n",
      "Processing scenes:  53%|█████▎    | 216/408 [11:47<06:37,  2.07s/it]\u001B[A\n",
      "Processing scenes:  53%|█████▎    | 217/408 [11:51<08:13,  2.58s/it]\u001B[A\n",
      "Processing scenes:  53%|█████▎    | 218/408 [11:54<08:32,  2.70s/it]\u001B[A\n",
      "Processing scenes:  54%|█████▎    | 219/408 [11:56<08:03,  2.56s/it]\u001B[A\n",
      "Processing scenes:  54%|█████▍    | 220/408 [12:46<52:20, 16.70s/it]\u001B[A\n",
      "Processing scenes:  54%|█████▍    | 221/408 [12:48<38:08, 12.24s/it]\u001B[A\n",
      "Processing scenes:  54%|█████▍    | 222/408 [12:50<28:56,  9.33s/it]\u001B[A\n",
      "Processing scenes:  55%|█████▍    | 223/408 [12:52<21:50,  7.08s/it]\u001B[A\n",
      "Processing scenes:  55%|█████▍    | 224/408 [12:54<17:11,  5.61s/it]\u001B[A\n",
      "Processing scenes:  55%|█████▌    | 225/408 [12:57<14:03,  4.61s/it]\u001B[A\n",
      "Processing scenes:  55%|█████▌    | 226/408 [12:59<11:30,  3.79s/it]\u001B[A\n",
      "Processing scenes:  56%|█████▌    | 227/408 [13:00<09:17,  3.08s/it]\u001B[A\n",
      "Processing scenes:  56%|█████▌    | 228/408 [13:04<09:57,  3.32s/it]\u001B[A\n",
      "Processing scenes:  56%|█████▌    | 229/408 [13:06<09:09,  3.07s/it]\u001B[A\n",
      "Processing scenes:  56%|█████▋    | 230/408 [13:10<09:32,  3.21s/it]\u001B[A\n",
      "Processing scenes:  57%|█████▋    | 231/408 [13:12<08:37,  2.93s/it]\u001B[A\n",
      "Processing scenes:  57%|█████▋    | 232/408 [13:14<07:44,  2.64s/it]\u001B[A\n",
      "Processing scenes:  57%|█████▋    | 233/408 [13:16<07:03,  2.42s/it]\u001B[A\n",
      "Processing scenes:  57%|█████▋    | 234/408 [13:18<06:28,  2.23s/it]\u001B[A\n",
      "Processing scenes:  58%|█████▊    | 235/408 [13:21<06:57,  2.42s/it]\u001B[A\n",
      "Processing scenes:  58%|█████▊    | 236/408 [13:24<07:53,  2.75s/it]\u001B[A\n",
      "Processing scenes:  58%|█████▊    | 237/408 [13:26<07:01,  2.47s/it]\u001B[A\n",
      "Processing scenes:  58%|█████▊    | 238/408 [13:29<07:12,  2.54s/it]\u001B[A\n",
      "Processing scenes:  59%|█████▊    | 239/408 [13:31<06:32,  2.32s/it]\u001B[A\n",
      "Processing scenes:  59%|█████▉    | 240/408 [13:32<05:59,  2.14s/it]\u001B[A\n",
      "Processing scenes:  59%|█████▉    | 241/408 [13:36<06:57,  2.50s/it]\u001B[A\n",
      "Processing scenes:  59%|█████▉    | 242/408 [13:41<09:01,  3.26s/it]\u001B[A\n",
      "Processing scenes:  60%|█████▉    | 243/408 [13:44<08:41,  3.16s/it]\u001B[A\n",
      "Processing scenes:  60%|█████▉    | 244/408 [13:47<09:13,  3.38s/it]\u001B[A\n",
      "Processing scenes:  60%|██████    | 245/408 [13:51<09:15,  3.41s/it]\u001B[A\n",
      "Processing scenes:  60%|██████    | 246/408 [13:53<08:24,  3.12s/it]\u001B[A\n",
      "Processing scenes:  61%|██████    | 247/408 [13:55<07:25,  2.76s/it]\u001B[A\n",
      "Processing scenes:  61%|██████    | 248/408 [13:59<08:19,  3.12s/it]\u001B[A\n",
      "Processing scenes:  61%|██████    | 249/408 [14:03<09:00,  3.40s/it]\u001B[A\n",
      "Processing scenes:  61%|██████▏   | 250/408 [14:08<09:46,  3.71s/it]\u001B[A\n",
      "Processing scenes:  62%|██████▏   | 251/408 [14:13<10:44,  4.11s/it]\u001B[A\n",
      "Processing scenes:  62%|██████▏   | 252/408 [14:16<09:57,  3.83s/it]\u001B[A\n",
      "Processing scenes:  62%|██████▏   | 253/408 [14:20<09:54,  3.83s/it]\u001B[A\n",
      "Processing scenes:  62%|██████▏   | 254/408 [14:23<08:57,  3.49s/it]\u001B[A\n",
      "Processing scenes:  62%|██████▎   | 255/408 [14:26<08:55,  3.50s/it]\u001B[A\n",
      "Processing scenes:  63%|██████▎   | 256/408 [14:28<07:26,  2.94s/it]\u001B[A\n",
      "Processing scenes:  63%|██████▎   | 257/408 [14:30<06:41,  2.66s/it]\u001B[A\n",
      "Processing scenes:  63%|██████▎   | 258/408 [14:31<05:41,  2.28s/it]\u001B[A\n",
      "Processing scenes:  63%|██████▎   | 259/408 [14:33<05:37,  2.27s/it]\u001B[A\n",
      "Processing scenes:  64%|██████▎   | 260/408 [14:38<07:05,  2.88s/it]\u001B[A\n",
      "Processing scenes:  64%|██████▍   | 261/408 [14:39<06:03,  2.47s/it]\u001B[A\n",
      "Processing scenes:  64%|██████▍   | 262/408 [14:42<06:34,  2.70s/it]\u001B[A\n",
      "Processing scenes:  64%|██████▍   | 263/408 [14:48<08:18,  3.44s/it]\u001B[A\n",
      "Processing scenes:  65%|██████▍   | 264/408 [14:52<08:39,  3.61s/it]\u001B[A\n",
      "Processing scenes:  65%|██████▍   | 265/408 [14:53<07:10,  3.01s/it]\u001B[A\n",
      "Processing scenes:  65%|██████▌   | 266/408 [14:57<07:39,  3.24s/it]\u001B[A\n",
      "Processing scenes:  65%|██████▌   | 267/408 [14:59<06:36,  2.81s/it]\u001B[A\n",
      "Processing scenes:  66%|██████▌   | 268/408 [15:01<06:27,  2.77s/it]\u001B[A\n",
      "Processing scenes:  66%|██████▌   | 269/408 [15:05<06:58,  3.01s/it]\u001B[A\n",
      "Processing scenes:  66%|██████▌   | 270/408 [15:09<07:16,  3.17s/it]\u001B[A\n",
      "Processing scenes:  66%|██████▋   | 271/408 [15:11<06:43,  2.95s/it]\u001B[A\n",
      "Processing scenes:  67%|██████▋   | 272/408 [15:14<06:46,  2.99s/it]\u001B[A\n",
      "Processing scenes:  67%|██████▋   | 273/408 [15:16<06:20,  2.82s/it]\u001B[A\n",
      "Processing scenes:  67%|██████▋   | 274/408 [15:18<05:40,  2.54s/it]\u001B[A\n",
      "Processing scenes:  67%|██████▋   | 275/408 [15:22<06:11,  2.79s/it]\u001B[A\n",
      "Processing scenes:  68%|██████▊   | 276/408 [15:25<06:32,  2.98s/it]\u001B[A\n",
      "Processing scenes:  68%|██████▊   | 277/408 [15:29<07:07,  3.26s/it]\u001B[A\n",
      "Processing scenes:  68%|██████▊   | 278/408 [15:34<07:51,  3.63s/it]\u001B[A\n",
      "Processing scenes:  68%|██████▊   | 279/408 [15:36<07:13,  3.36s/it]\u001B[A\n",
      "Processing scenes:  69%|██████▊   | 280/408 [15:40<07:22,  3.46s/it]\u001B[A\n",
      "Processing scenes:  69%|██████▉   | 281/408 [15:44<07:42,  3.65s/it]\u001B[A\n",
      "Processing scenes:  69%|██████▉   | 282/408 [15:48<07:48,  3.72s/it]\u001B[A\n",
      "Processing scenes:  69%|██████▉   | 283/408 [15:51<07:00,  3.36s/it]\u001B[A\n",
      "Processing scenes:  70%|██████▉   | 284/408 [15:54<07:08,  3.45s/it]\u001B[A\n",
      "Processing scenes:  70%|██████▉   | 285/408 [15:58<07:09,  3.49s/it]\u001B[A\n",
      "Processing scenes:  70%|███████   | 286/408 [16:02<07:30,  3.70s/it]\u001B[A\n",
      "Processing scenes:  70%|███████   | 287/408 [16:06<07:50,  3.89s/it]\u001B[A\n",
      "Processing scenes:  71%|███████   | 288/408 [16:09<07:04,  3.54s/it]\u001B[A\n",
      "Processing scenes:  71%|███████   | 289/408 [16:12<06:42,  3.38s/it]\u001B[A\n",
      "Processing scenes:  71%|███████   | 290/408 [16:14<05:50,  2.97s/it]\u001B[A\n",
      "Processing scenes:  71%|███████▏  | 291/408 [16:17<05:50,  2.99s/it]\u001B[A\n",
      "Processing scenes:  72%|███████▏  | 292/408 [16:21<06:09,  3.19s/it]\u001B[A\n",
      "Processing scenes:  72%|███████▏  | 293/408 [16:24<06:11,  3.23s/it]\u001B[A\n",
      "Processing scenes:  72%|███████▏  | 294/408 [16:28<06:31,  3.43s/it]\u001B[A\n",
      "Processing scenes:  72%|███████▏  | 295/408 [16:29<05:21,  2.85s/it]\u001B[A\n",
      "Processing scenes:  73%|███████▎  | 296/408 [16:32<04:55,  2.64s/it]\u001B[A\n",
      "Processing scenes:  73%|███████▎  | 297/408 [16:34<04:29,  2.43s/it]\u001B[A\n",
      "Processing scenes:  73%|███████▎  | 298/408 [16:36<04:21,  2.38s/it]\u001B[A\n",
      "Processing scenes:  73%|███████▎  | 299/408 [16:38<03:58,  2.19s/it]\u001B[A\n",
      "Processing scenes:  74%|███████▎  | 300/408 [16:41<04:32,  2.52s/it]\u001B[A\n",
      "Processing scenes:  74%|███████▍  | 301/408 [16:44<05:01,  2.82s/it]\u001B[A\n",
      "Processing scenes:  74%|███████▍  | 302/408 [16:48<05:18,  3.00s/it]\u001B[A\n",
      "Processing scenes:  74%|███████▍  | 303/408 [16:50<04:50,  2.77s/it]\u001B[A\n",
      "Processing scenes:  75%|███████▍  | 304/408 [16:53<05:00,  2.89s/it]\u001B[A\n",
      "Processing scenes:  75%|███████▍  | 305/408 [16:56<05:11,  3.03s/it]\u001B[A\n",
      "Processing scenes:  75%|███████▌  | 306/408 [16:59<04:56,  2.91s/it]\u001B[A\n",
      "Processing scenes:  75%|███████▌  | 307/408 [17:01<04:13,  2.51s/it]\u001B[A\n",
      "Processing scenes:  75%|███████▌  | 308/408 [17:05<05:16,  3.17s/it]\u001B[A\n",
      "Processing scenes:  76%|███████▌  | 309/408 [17:09<05:38,  3.42s/it]\u001B[A\n",
      "Processing scenes:  76%|███████▌  | 310/408 [17:12<05:21,  3.29s/it]\u001B[A\n",
      "Processing scenes:  76%|███████▌  | 311/408 [17:17<05:49,  3.61s/it]\u001B[A\n",
      "Processing scenes:  76%|███████▋  | 312/408 [17:21<05:52,  3.68s/it]\u001B[A\n",
      "Processing scenes:  77%|███████▋  | 313/408 [17:22<04:44,  3.00s/it]\u001B[A\n",
      "Processing scenes:  77%|███████▋  | 314/408 [17:26<05:01,  3.21s/it]\u001B[A\n",
      "Processing scenes:  77%|███████▋  | 315/408 [17:29<04:51,  3.14s/it]\u001B[A\n",
      "Processing scenes:  77%|███████▋  | 316/408 [17:31<04:23,  2.87s/it]\u001B[A\n",
      "Processing scenes:  78%|███████▊  | 317/408 [17:33<03:49,  2.52s/it]\u001B[A\n",
      "Processing scenes:  78%|███████▊  | 318/408 [17:37<04:28,  2.99s/it]\u001B[A\n",
      "Processing scenes:  78%|███████▊  | 319/408 [17:40<04:41,  3.16s/it]\u001B[A\n",
      "Processing scenes:  78%|███████▊  | 320/408 [17:44<04:44,  3.24s/it]\u001B[A\n",
      "Processing scenes:  79%|███████▊  | 321/408 [17:47<04:53,  3.37s/it]\u001B[A\n",
      "Processing scenes:  79%|███████▉  | 322/408 [17:51<04:57,  3.46s/it]\u001B[A\n",
      "Processing scenes:  79%|███████▉  | 323/408 [17:55<05:03,  3.57s/it]\u001B[A\n",
      "Processing scenes:  79%|███████▉  | 324/408 [17:59<05:13,  3.74s/it]\u001B[A\n",
      "Processing scenes:  80%|███████▉  | 325/408 [18:03<05:15,  3.80s/it]\u001B[A\n",
      "Processing scenes:  80%|███████▉  | 326/408 [18:06<05:02,  3.69s/it]\u001B[A\n",
      "Processing scenes:  80%|████████  | 327/408 [18:09<04:45,  3.52s/it]\u001B[A\n",
      "Processing scenes:  80%|████████  | 328/408 [18:13<04:49,  3.61s/it]\u001B[A\n",
      "Processing scenes:  81%|████████  | 329/408 [18:17<04:53,  3.72s/it]\u001B[A\n",
      "Processing scenes:  81%|████████  | 330/408 [18:21<04:41,  3.61s/it]\u001B[A\n",
      "Processing scenes:  81%|████████  | 331/408 [18:23<04:00,  3.13s/it]\u001B[A\n",
      "Processing scenes:  81%|████████▏ | 332/408 [18:26<04:12,  3.32s/it]\u001B[A\n",
      "Processing scenes:  82%|████████▏ | 333/408 [18:29<03:42,  2.97s/it]\u001B[A\n",
      "Processing scenes:  82%|████████▏ | 334/408 [18:32<03:45,  3.04s/it]\u001B[A\n",
      "Processing scenes:  82%|████████▏ | 335/408 [18:36<04:00,  3.29s/it]\u001B[A\n",
      "Processing scenes:  82%|████████▏ | 336/408 [18:39<04:00,  3.34s/it]\u001B[A\n",
      "Processing scenes:  83%|████████▎ | 337/408 [18:43<04:04,  3.44s/it]\u001B[A\n",
      "Processing scenes:  83%|████████▎ | 338/408 [18:48<04:33,  3.90s/it]\u001B[A\n",
      "Processing scenes:  83%|████████▎ | 339/408 [18:50<03:54,  3.39s/it]\u001B[A\n",
      "Processing scenes:  83%|████████▎ | 340/408 [18:54<03:58,  3.51s/it]\u001B[A\n",
      "Processing scenes:  84%|████████▎ | 341/408 [18:56<03:23,  3.03s/it]\u001B[A\n",
      "Processing scenes:  84%|████████▍ | 342/408 [18:59<03:32,  3.21s/it]\u001B[A\n",
      "Processing scenes:  84%|████████▍ | 343/408 [19:04<03:50,  3.54s/it]\u001B[A\n",
      "Processing scenes:  84%|████████▍ | 344/408 [19:08<04:07,  3.87s/it]\u001B[A\n",
      "Processing scenes:  85%|████████▍ | 345/408 [19:12<03:58,  3.79s/it]\u001B[A\n",
      "Processing scenes:  85%|████████▍ | 346/408 [19:15<03:34,  3.46s/it]\u001B[A\n",
      "Processing scenes:  85%|████████▌ | 347/408 [19:16<03:03,  3.01s/it]\u001B[A\n",
      "Processing scenes:  85%|████████▌ | 348/408 [19:18<02:37,  2.63s/it]\u001B[A\n",
      "Processing scenes:  86%|████████▌ | 349/408 [19:22<02:57,  3.00s/it]\u001B[A\n",
      "Processing scenes:  86%|████████▌ | 350/408 [19:24<02:42,  2.80s/it]\u001B[A\n",
      "Processing scenes:  86%|████████▌ | 351/408 [19:27<02:35,  2.72s/it]\u001B[A\n",
      "Processing scenes:  86%|████████▋ | 352/408 [19:30<02:30,  2.68s/it]\u001B[A\n",
      "Processing scenes:  87%|████████▋ | 353/408 [19:31<02:11,  2.38s/it]\u001B[A\n",
      "Processing scenes:  87%|████████▋ | 354/408 [19:34<02:22,  2.63s/it]\u001B[A\n",
      "Processing scenes:  87%|████████▋ | 355/408 [19:37<02:12,  2.50s/it]\u001B[A\n",
      "Processing scenes:  87%|████████▋ | 356/408 [19:39<02:00,  2.32s/it]\u001B[A\n",
      "Processing scenes:  88%|████████▊ | 357/408 [19:43<02:34,  3.02s/it]\u001B[A\n",
      "Processing scenes:  88%|████████▊ | 358/408 [19:45<02:16,  2.74s/it]\u001B[A\n",
      "Processing scenes:  88%|████████▊ | 359/408 [19:49<02:31,  3.09s/it]\u001B[A\n",
      "Processing scenes:  88%|████████▊ | 360/408 [19:53<02:38,  3.31s/it]\u001B[A\n",
      "Processing scenes:  88%|████████▊ | 361/408 [19:56<02:33,  3.27s/it]\u001B[A\n",
      "Processing scenes:  89%|████████▊ | 362/408 [20:00<02:42,  3.53s/it]\u001B[A\n",
      "Processing scenes:  89%|████████▉ | 363/408 [20:04<02:46,  3.69s/it]\u001B[A\n",
      "Processing scenes:  89%|████████▉ | 364/408 [20:09<02:48,  3.84s/it]\u001B[A\n",
      "Processing scenes:  89%|████████▉ | 365/408 [20:10<02:17,  3.19s/it]\u001B[A\n",
      "Processing scenes:  90%|████████▉ | 366/408 [20:12<01:55,  2.74s/it]\u001B[A\n",
      "Processing scenes:  90%|████████▉ | 367/408 [20:14<01:42,  2.50s/it]\u001B[A\n",
      "Processing scenes:  90%|█████████ | 368/408 [20:16<01:32,  2.30s/it]\u001B[A\n",
      "Processing scenes:  90%|█████████ | 369/408 [20:18<01:24,  2.16s/it]\u001B[A\n",
      "Processing scenes:  91%|█████████ | 370/408 [20:19<01:17,  2.04s/it]\u001B[A\n",
      "Processing scenes:  91%|█████████ | 371/408 [20:22<01:26,  2.33s/it]\u001B[A\n",
      "Processing scenes:  91%|█████████ | 372/408 [20:25<01:28,  2.47s/it]\u001B[A\n",
      "Processing scenes:  91%|█████████▏| 373/408 [20:27<01:25,  2.43s/it]\u001B[A\n",
      "Processing scenes:  92%|█████████▏| 374/408 [20:32<01:46,  3.13s/it]\u001B[A\n",
      "Processing scenes:  92%|█████████▏| 375/408 [20:35<01:41,  3.08s/it]\u001B[A\n",
      "Processing scenes:  92%|█████████▏| 376/408 [20:37<01:25,  2.67s/it]\u001B[A\n",
      "Processing scenes:  92%|█████████▏| 377/408 [20:42<01:41,  3.29s/it]\u001B[A\n",
      "Processing scenes:  93%|█████████▎| 378/408 [20:44<01:32,  3.09s/it]\u001B[A\n",
      "Processing scenes:  93%|█████████▎| 379/408 [20:48<01:38,  3.40s/it]\u001B[A\n",
      "Processing scenes:  93%|█████████▎| 380/408 [20:53<01:42,  3.67s/it]\u001B[A\n",
      "Processing scenes:  93%|█████████▎| 381/408 [20:57<01:43,  3.85s/it]\u001B[A\n",
      "Processing scenes:  94%|█████████▎| 382/408 [20:59<01:29,  3.44s/it]\u001B[A\n",
      "Processing scenes:  94%|█████████▍| 383/408 [21:02<01:16,  3.07s/it]\u001B[A\n",
      "Processing scenes:  94%|█████████▍| 384/408 [21:06<01:19,  3.32s/it]\u001B[A\n",
      "Processing scenes:  94%|█████████▍| 385/408 [21:07<01:03,  2.75s/it]\u001B[A\n",
      "Processing scenes:  95%|█████████▍| 386/408 [21:08<00:52,  2.39s/it]\u001B[A\n",
      "Processing scenes:  95%|█████████▍| 387/408 [21:12<00:53,  2.57s/it]\u001B[A\n",
      "Processing scenes:  95%|█████████▌| 388/408 [21:15<00:59,  2.97s/it]\u001B[A\n",
      "Processing scenes:  95%|█████████▌| 389/408 [21:17<00:47,  2.51s/it]\u001B[A\n",
      "Processing scenes:  96%|█████████▌| 390/408 [21:21<00:56,  3.13s/it]\u001B[A\n",
      "Processing scenes:  96%|█████████▌| 391/408 [21:23<00:45,  2.66s/it]\u001B[A\n",
      "Processing scenes:  96%|█████████▌| 392/408 [21:26<00:43,  2.73s/it]\u001B[A\n",
      "Processing scenes:  96%|█████████▋| 393/408 [21:29<00:44,  2.94s/it]\u001B[A\n",
      "Processing scenes:  97%|█████████▋| 394/408 [21:34<00:48,  3.43s/it]\u001B[A\n",
      "Processing scenes:  97%|█████████▋| 395/408 [21:36<00:40,  3.13s/it]\u001B[A\n",
      "Processing scenes:  97%|█████████▋| 396/408 [21:40<00:38,  3.21s/it]\u001B[A\n",
      "Processing scenes:  97%|█████████▋| 397/408 [21:43<00:36,  3.33s/it]\u001B[A\n",
      "Processing scenes:  98%|█████████▊| 398/408 [21:47<00:33,  3.34s/it]\u001B[A\n",
      "Processing scenes:  98%|█████████▊| 399/408 [21:51<00:32,  3.58s/it]\u001B[A\n",
      "Processing scenes:  98%|█████████▊| 400/408 [21:53<00:24,  3.08s/it]\u001B[A\n",
      "Processing scenes:  98%|█████████▊| 401/408 [21:56<00:21,  3.04s/it]\u001B[A\n",
      "Processing scenes:  99%|█████████▊| 402/408 [22:00<00:20,  3.42s/it]\u001B[A\n",
      "Processing scenes:  99%|█████████▉| 403/408 [22:02<00:14,  2.90s/it]\u001B[A\n",
      "Processing scenes:  99%|█████████▉| 404/408 [22:04<00:11,  2.80s/it]\u001B[A\n",
      "Processing scenes:  99%|█████████▉| 405/408 [22:06<00:07,  2.43s/it]\u001B[A\n",
      "Processing scenes: 100%|█████████▉| 406/408 [22:07<00:04,  2.14s/it]\u001B[A\n",
      "Processing scenes: 100%|█████████▉| 407/408 [22:11<00:02,  2.49s/it]\u001B[A\n",
      "Processing scenes: 100%|██████████| 408/408 [22:15<00:00,  3.27s/it]\u001B[A\n",
      "Processing scene files:   1%|          | 11/1210 [22:15<40:27:00, 121.45s/it]\n",
      "Processing scenes:   0%|          | 0/268 [00:00<?, ?it/s]\u001B[A\n",
      "Processing scenes:   0%|          | 1/268 [00:02<10:48,  2.43s/it]\u001B[A\n",
      "Processing scenes:   1%|          | 2/268 [00:49<2:06:16, 28.48s/it]\u001B[A\n",
      "Processing scenes:   1%|          | 3/268 [00:51<1:13:35, 16.66s/it]\u001B[A\n",
      "Processing scenes:   1%|▏         | 4/268 [00:54<48:47, 11.09s/it]  \u001B[A\n",
      "Processing scenes:   2%|▏         | 5/268 [00:56<35:15,  8.04s/it]\u001B[A\n",
      "Processing scenes:   2%|▏         | 6/268 [00:58<25:40,  5.88s/it]\u001B[A\n",
      "Processing scenes:   3%|▎         | 7/268 [00:59<18:58,  4.36s/it]\u001B[A\n",
      "Processing scenes:   3%|▎         | 8/268 [01:03<17:58,  4.15s/it]\u001B[A\n",
      "Processing scenes:   3%|▎         | 9/268 [01:07<17:09,  3.98s/it]\u001B[A\n",
      "Processing scenes:   4%|▎         | 10/268 [01:08<13:52,  3.23s/it]\u001B[A\n",
      "Processing scenes:   4%|▍         | 11/268 [01:11<13:27,  3.14s/it]\u001B[A\n",
      "Processing scenes:   4%|▍         | 12/268 [01:13<11:31,  2.70s/it]\u001B[A\n",
      "Processing scenes:   5%|▍         | 13/268 [01:14<09:35,  2.26s/it]\u001B[A\n",
      "Processing scenes:   5%|▌         | 14/268 [01:16<09:36,  2.27s/it]\u001B[A\n",
      "Processing scenes:   6%|▌         | 15/268 [01:19<09:35,  2.27s/it]\u001B[A\n",
      "Processing scenes:   6%|▌         | 16/268 [01:21<09:09,  2.18s/it]\u001B[A\n",
      "Processing scenes:   6%|▋         | 17/268 [01:23<08:53,  2.13s/it]\u001B[A\n",
      "Processing scenes:   7%|▋         | 18/268 [01:25<09:24,  2.26s/it]\u001B[A\n",
      "Processing scenes:   7%|▋         | 19/268 [01:27<09:17,  2.24s/it]\u001B[A\n",
      "Processing scenes:   7%|▋         | 20/268 [01:32<12:37,  3.05s/it]\u001B[A\n",
      "Processing scenes:   8%|▊         | 21/268 [01:34<10:49,  2.63s/it]\u001B[A\n",
      "Processing scenes:   8%|▊         | 22/268 [01:37<11:51,  2.89s/it]\u001B[A\n",
      "Processing scenes:   9%|▊         | 23/268 [01:40<11:57,  2.93s/it]\u001B[A\n",
      "Processing scenes:   9%|▉         | 24/268 [01:43<11:14,  2.76s/it]\u001B[A\n",
      "Processing scenes:   9%|▉         | 25/268 [01:45<10:23,  2.57s/it]\u001B[A\n",
      "Processing scenes:  10%|▉         | 26/268 [01:49<11:41,  2.90s/it]\u001B[A\n",
      "Processing scenes:  10%|█         | 27/268 [01:52<12:06,  3.01s/it]\u001B[A\n",
      "Processing scenes:  10%|█         | 28/268 [01:54<10:57,  2.74s/it]\u001B[A\n",
      "Processing scenes:  11%|█         | 29/268 [01:58<11:49,  2.97s/it]\u001B[A\n",
      "Processing scenes:  11%|█         | 30/268 [01:59<10:30,  2.65s/it]\u001B[A\n",
      "Processing scenes:  12%|█▏        | 31/268 [02:03<12:00,  3.04s/it]\u001B[A\n",
      "Processing scenes:  12%|█▏        | 32/268 [02:06<11:27,  2.92s/it]\u001B[A\n",
      "Processing scenes:  12%|█▏        | 33/268 [02:09<11:06,  2.83s/it]\u001B[A\n",
      "Processing scenes:  13%|█▎        | 34/268 [02:12<11:29,  2.95s/it]\u001B[A\n",
      "Processing scenes:  13%|█▎        | 35/268 [02:15<11:56,  3.07s/it]\u001B[A\n",
      "Processing scenes:  13%|█▎        | 36/268 [02:19<13:08,  3.40s/it]\u001B[A\n",
      "Processing scenes:  14%|█▍        | 37/268 [02:24<14:30,  3.77s/it]\u001B[A\n",
      "Processing scenes:  14%|█▍        | 38/268 [02:28<14:31,  3.79s/it]\u001B[A\n",
      "Processing scenes:  15%|█▍        | 39/268 [02:29<11:49,  3.10s/it]\u001B[A\n",
      "Processing scenes:  15%|█▍        | 40/268 [02:31<10:21,  2.73s/it]\u001B[A\n",
      "Processing scenes:  15%|█▌        | 41/268 [02:34<10:25,  2.76s/it]\u001B[A\n",
      "Processing scenes:  16%|█▌        | 42/268 [02:38<11:35,  3.08s/it]\u001B[A\n",
      "Processing scenes:  16%|█▌        | 43/268 [02:41<11:59,  3.20s/it]\u001B[A\n",
      "Processing scenes:  16%|█▋        | 44/268 [02:46<13:12,  3.54s/it]\u001B[A\n",
      "Processing scenes:  17%|█▋        | 45/268 [02:49<12:49,  3.45s/it]\u001B[A\n",
      "Processing scenes:  17%|█▋        | 46/268 [02:51<11:45,  3.18s/it]\u001B[A\n",
      "Processing scenes:  18%|█▊        | 47/268 [02:54<11:33,  3.14s/it]\u001B[A\n",
      "Processing scenes:  18%|█▊        | 48/268 [02:59<12:38,  3.45s/it]\u001B[A\n",
      "Processing scenes:  18%|█▊        | 49/268 [03:00<10:44,  2.94s/it]\u001B[A\n",
      "Processing scenes:  19%|█▊        | 50/268 [03:03<10:28,  2.88s/it]\u001B[A\n",
      "Processing scenes:  19%|█▉        | 51/268 [03:05<09:41,  2.68s/it]\u001B[A\n",
      "Processing scenes:  19%|█▉        | 52/268 [03:08<09:35,  2.66s/it]\u001B[A\n",
      "Processing scenes:  20%|█▉        | 53/268 [03:12<10:27,  2.92s/it]\u001B[A\n",
      "Processing scenes:  20%|██        | 54/268 [03:14<09:39,  2.71s/it]\u001B[A\n",
      "Processing scenes:  21%|██        | 55/268 [03:16<09:19,  2.63s/it]\u001B[A\n",
      "Processing scenes:  21%|██        | 56/268 [03:18<08:53,  2.52s/it]\u001B[A\n",
      "Processing scenes:  21%|██▏       | 57/268 [03:21<08:37,  2.45s/it]\u001B[A\n",
      "Processing scenes:  22%|██▏       | 58/268 [03:23<07:54,  2.26s/it]\u001B[A\n",
      "Processing scenes:  22%|██▏       | 59/268 [03:25<07:40,  2.20s/it]\u001B[A\n",
      "Processing scenes:  22%|██▏       | 60/268 [03:27<07:56,  2.29s/it]\u001B[A\n",
      "Processing scenes:  23%|██▎       | 61/268 [03:29<11:52,  3.44s/it]\u001B[A\n",
      "Processing scene files:   1%|          | 11/1210 [25:45<46:48:26, 140.54s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[95], line 22\u001B[0m\n\u001B[1;32m     20\u001B[0m end_frame \u001B[38;5;241m=\u001B[39m scene_data[i][\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 22\u001B[0m     \u001B[43mcut_video\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvideo_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcut_output_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstart_frame\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mend_frame\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m  \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     24\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[90], line 7\u001B[0m, in \u001B[0;36mcut_video\u001B[0;34m(input_file, output_file, start_frame, end_frame)\u001B[0m\n\u001B[1;32m      5\u001B[0m end_time \u001B[38;5;241m=\u001B[39m end_frame \u001B[38;5;241m/\u001B[39m fps\n\u001B[1;32m      6\u001B[0m cut_clip \u001B[38;5;241m=\u001B[39m clip\u001B[38;5;241m.\u001B[39msubclip(start_time, end_time)\n\u001B[0;32m----> 7\u001B[0m \u001B[43mcut_clip\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrite_videofile\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcodec\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlibx264\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogger\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m<decorator-gen-73>:2\u001B[0m, in \u001B[0;36mwrite_videofile\u001B[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, logger)\u001B[0m\n",
      "File \u001B[0;32m~/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages/moviepy/decorators.py:54\u001B[0m, in \u001B[0;36mrequires_duration\u001B[0;34m(f, clip, *a, **k)\u001B[0m\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAttribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mduration\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m not set\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 54\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclip\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mk\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m<decorator-gen-72>:2\u001B[0m, in \u001B[0;36mwrite_videofile\u001B[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, logger)\u001B[0m\n",
      "File \u001B[0;32m~/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages/moviepy/decorators.py:135\u001B[0m, in \u001B[0;36muse_clip_fps_by_default\u001B[0;34m(f, clip, *a, **k)\u001B[0m\n\u001B[1;32m    130\u001B[0m new_a \u001B[38;5;241m=\u001B[39m [fun(arg) \u001B[38;5;28;01mif\u001B[39;00m (name\u001B[38;5;241m==\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfps\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m arg\n\u001B[1;32m    131\u001B[0m          \u001B[38;5;28;01mfor\u001B[39;00m (arg, name) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(a, names)]\n\u001B[1;32m    132\u001B[0m new_kw \u001B[38;5;241m=\u001B[39m {k: fun(v) \u001B[38;5;28;01mif\u001B[39;00m k\u001B[38;5;241m==\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfps\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m v\n\u001B[1;32m    133\u001B[0m          \u001B[38;5;28;01mfor\u001B[39;00m (k,v) \u001B[38;5;129;01min\u001B[39;00m k\u001B[38;5;241m.\u001B[39mitems()}\n\u001B[0;32m--> 135\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclip\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mnew_a\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mnew_kw\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m<decorator-gen-71>:2\u001B[0m, in \u001B[0;36mwrite_videofile\u001B[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, logger)\u001B[0m\n",
      "File \u001B[0;32m~/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages/moviepy/decorators.py:22\u001B[0m, in \u001B[0;36mconvert_masks_to_RGB\u001B[0;34m(f, clip, *a, **k)\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m clip\u001B[38;5;241m.\u001B[39mismask:\n\u001B[1;32m     21\u001B[0m     clip \u001B[38;5;241m=\u001B[39m clip\u001B[38;5;241m.\u001B[39mto_RGB()\n\u001B[0;32m---> 22\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclip\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mk\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages/moviepy/video/VideoClip.py:300\u001B[0m, in \u001B[0;36mVideoClip.write_videofile\u001B[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, logger)\u001B[0m\n\u001B[1;32m    292\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m make_audio:\n\u001B[1;32m    293\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maudio\u001B[38;5;241m.\u001B[39mwrite_audiofile(audiofile, audio_fps,\n\u001B[1;32m    294\u001B[0m                                audio_nbytes, audio_bufsize,\n\u001B[1;32m    295\u001B[0m                                audio_codec, bitrate\u001B[38;5;241m=\u001B[39maudio_bitrate,\n\u001B[1;32m    296\u001B[0m                                write_logfile\u001B[38;5;241m=\u001B[39mwrite_logfile,\n\u001B[1;32m    297\u001B[0m                                verbose\u001B[38;5;241m=\u001B[39mverbose,\n\u001B[1;32m    298\u001B[0m                                logger\u001B[38;5;241m=\u001B[39mlogger)\n\u001B[0;32m--> 300\u001B[0m \u001B[43mffmpeg_write_video\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfps\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcodec\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    301\u001B[0m \u001B[43m                   \u001B[49m\u001B[43mbitrate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbitrate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    302\u001B[0m \u001B[43m                   \u001B[49m\u001B[43mpreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpreset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    303\u001B[0m \u001B[43m                   \u001B[49m\u001B[43mwrite_logfile\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwrite_logfile\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    304\u001B[0m \u001B[43m                   \u001B[49m\u001B[43maudiofile\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maudiofile\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    305\u001B[0m \u001B[43m                   \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mthreads\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mthreads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    306\u001B[0m \u001B[43m                   \u001B[49m\u001B[43mffmpeg_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mffmpeg_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    307\u001B[0m \u001B[43m                   \u001B[49m\u001B[43mlogger\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlogger\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    309\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m remove_temp \u001B[38;5;129;01mand\u001B[39;00m make_audio:\n\u001B[1;32m    310\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(audiofile):\n",
      "File \u001B[0;32m~/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages/moviepy/video/io/ffmpeg_writer.py:228\u001B[0m, in \u001B[0;36mffmpeg_write_video\u001B[0;34m(clip, filename, fps, codec, bitrate, preset, withmask, write_logfile, audiofile, verbose, threads, ffmpeg_params, logger)\u001B[0m\n\u001B[1;32m    225\u001B[0m                 mask \u001B[38;5;241m=\u001B[39m mask\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muint8\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    226\u001B[0m             frame \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mdstack([frame,mask])\n\u001B[0;32m--> 228\u001B[0m         \u001B[43mwriter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrite_frame\u001B[49m\u001B[43m(\u001B[49m\u001B[43mframe\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    230\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m write_logfile:\n\u001B[1;32m    231\u001B[0m     logfile\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m~/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages/moviepy/video/io/ffmpeg_writer.py:136\u001B[0m, in \u001B[0;36mFFMPEG_VideoWriter.write_frame\u001B[0;34m(self, img_array)\u001B[0m\n\u001B[1;32m    134\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    135\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m PY3:\n\u001B[0;32m--> 136\u001B[0m        \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mproc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstdin\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrite\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg_array\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtobytes\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    137\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    138\u001B[0m        \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mproc\u001B[38;5;241m.\u001B[39mstdin\u001B[38;5;241m.\u001B[39mwrite(img_array\u001B[38;5;241m.\u001B[39mtostring())\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3b48232c57cf0b4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "422c8103be81a48e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
