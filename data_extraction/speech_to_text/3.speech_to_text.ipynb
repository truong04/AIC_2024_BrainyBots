{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-23T15:27:42.987045Z",
     "start_time": "2024-10-23T15:27:40.166978Z"
    }
   },
   "source": "!pip install transformers torchaudio torch librosa sentencepiece",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\r\n",
      "Requirement already satisfied: transformers in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (4.45.1)\r\n",
      "Requirement already satisfied: torchaudio in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (2.5.0)\r\n",
      "Requirement already satisfied: torch in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (2.5.0)\r\n",
      "Requirement already satisfied: librosa in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (0.10.2.post1)\r\n",
      "Requirement already satisfied: sentencepiece in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (0.1.99)\r\n",
      "Requirement already satisfied: filelock in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from transformers) (3.16.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from transformers) (0.23.4)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from transformers) (1.24.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from transformers) (24.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from transformers) (6.0.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from transformers) (2024.7.24)\r\n",
      "Requirement already satisfied: requests in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from transformers) (2.32.3)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from transformers) (0.4.4)\r\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from transformers) (0.20.0)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from transformers) (4.66.5)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from torch) (4.12.2)\r\n",
      "Requirement already satisfied: networkx in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from torch) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from torch) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from torch) (2024.10.0)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from torch) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from torch) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from torch) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from torch) (9.1.0.70)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from torch) (12.4.5.8)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from torch) (11.2.1.3)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from torch) (10.3.5.147)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from torch) (11.6.1.9)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from torch) (12.3.1.170)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from torch) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from torch) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from torch) (12.4.127)\r\n",
      "Requirement already satisfied: triton==3.1.0 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from torch) (3.1.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from torch) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\r\n",
      "Requirement already satisfied: audioread>=2.1.9 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from librosa) (3.0.1)\r\n",
      "Requirement already satisfied: scipy>=1.2.0 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from librosa) (1.14.0)\r\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from librosa) (1.5.1)\r\n",
      "Requirement already satisfied: joblib>=0.14 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from librosa) (1.4.2)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from librosa) (4.4.2)\r\n",
      "Requirement already satisfied: numba>=0.51.0 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from librosa) (0.60.0)\r\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from librosa) (0.12.1)\r\n",
      "Requirement already satisfied: pooch>=1.1 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from librosa) (1.8.2)\r\n",
      "Requirement already satisfied: soxr>=0.3.2 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from librosa) (0.4.0)\r\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from librosa) (0.4)\r\n",
      "Requirement already satisfied: msgpack>=1.0 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from librosa) (1.0.8)\r\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from numba>=0.51.0->librosa) (0.43.0)\r\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from pooch>=1.1->librosa) (4.2.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from requests->transformers) (2.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from requests->transformers) (2.2.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\r\n",
      "Requirement already satisfied: cffi>=1.0 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\r\n",
      "Requirement already satisfied: pycparser in /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T15:27:49.997273Z",
     "start_time": "2024-10-23T15:27:48.955276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import SpeechEncoderDecoderModel, AutoFeatureExtractor, AutoTokenizer, GenerationConfig\n",
    "import torchaudio\n",
    "import torch\n",
    "import librosa\n",
    "import json\n"
   ],
   "id": "a24243cc6ae2bc2d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T15:27:55.352669Z",
     "start_time": "2024-10-23T15:27:53.000344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_path = 'nguyenvulebinh/wav2vec2-bartpho'\n",
    "\n",
    "model = SpeechEncoderDecoderModel.from_pretrained(model_path).eval()\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ],
   "id": "81cde06a5c5f016e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SpeechEncoderDecoderModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models.wav2vec2.modeling_wav2vec2 because of the following error (look up to see its traceback):\n/home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops5zeros4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEE",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "File \u001B[0;32m~/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages/transformers/utils/import_utils.py:1764\u001B[0m, in \u001B[0;36m_LazyModule._get_module\u001B[0;34m(self, module_name)\u001B[0m\n\u001B[1;32m   1763\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1764\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mimportlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m.\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmodule_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__name__\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1765\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m/usr/lib/python3.10/importlib/__init__.py:126\u001B[0m, in \u001B[0;36mimport_module\u001B[0;34m(name, package)\u001B[0m\n\u001B[1;32m    125\u001B[0m         level \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m--> 126\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_bootstrap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gcd_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpackage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1050\u001B[0m, in \u001B[0;36m_gcd_import\u001B[0;34m(name, package, level)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1027\u001B[0m, in \u001B[0;36m_find_and_load\u001B[0;34m(name, import_)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1006\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[0;34m(name, import_)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:688\u001B[0m, in \u001B[0;36m_load_unlocked\u001B[0;34m(spec)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap_external>:883\u001B[0m, in \u001B[0;36mexec_module\u001B[0;34m(self, module)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:241\u001B[0m, in \u001B[0;36m_call_with_frames_removed\u001B[0;34m(f, *args, **kwds)\u001B[0m\n",
      "File \u001B[0;32m~/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:65\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_flash_attn_2_available():\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodeling_flash_attention_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _flash_attention_forward\n\u001B[1;32m     67\u001B[0m logger \u001B[38;5;241m=\u001B[39m logging\u001B[38;5;241m.\u001B[39mget_logger(\u001B[38;5;18m__name__\u001B[39m)\n",
      "File \u001B[0;32m~/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages/transformers/modeling_flash_attention_utils.py:27\u001B[0m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_flash_attn_2_available():\n\u001B[0;32m---> 27\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mflash_attn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbert_padding\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m index_first_axis, pad_input, unpad_input  \u001B[38;5;66;03m# noqa\u001B[39;00m\n\u001B[1;32m     28\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mflash_attn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m flash_attn_func, flash_attn_varlen_func\n",
      "File \u001B[0;32m~/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages/flash_attn/__init__.py:3\u001B[0m\n\u001B[1;32m      1\u001B[0m __version__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m2.6.3\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mflash_attn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mflash_attn_interface\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m      4\u001B[0m     flash_attn_func,\n\u001B[1;32m      5\u001B[0m     flash_attn_kvpacked_func,\n\u001B[1;32m      6\u001B[0m     flash_attn_qkvpacked_func,\n\u001B[1;32m      7\u001B[0m     flash_attn_varlen_func,\n\u001B[1;32m      8\u001B[0m     flash_attn_varlen_kvpacked_func,\n\u001B[1;32m      9\u001B[0m     flash_attn_varlen_qkvpacked_func,\n\u001B[1;32m     10\u001B[0m     flash_attn_with_kvcache,\n\u001B[1;32m     11\u001B[0m )\n",
      "File \u001B[0;32m~/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py:10\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# isort: off\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# We need to import the CUDA kernels after importing torch\u001B[39;00m\n\u001B[0;32m---> 10\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mflash_attn_2_cuda\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mflash_attn_cuda\u001B[39;00m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# isort: on\u001B[39;00m\n",
      "\u001B[0;31mImportError\u001B[0m: /home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops5zeros4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEE",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m model_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnguyenvulebinh/wav2vec2-bartpho\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m----> 3\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mSpeechEncoderDecoderModel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m      4\u001B[0m feature_extractor \u001B[38;5;241m=\u001B[39m AutoFeatureExtractor\u001B[38;5;241m.\u001B[39mfrom_pretrained(model_path)\n\u001B[1;32m      5\u001B[0m tokenizer \u001B[38;5;241m=\u001B[39m AutoTokenizer\u001B[38;5;241m.\u001B[39mfrom_pretrained(model_path)\n",
      "File \u001B[0;32m~/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages/transformers/models/speech_encoder_decoder/modeling_speech_encoder_decoder.py:281\u001B[0m, in \u001B[0;36mSpeechEncoderDecoderModel.from_pretrained\u001B[0;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[1;32m    276\u001B[0m     logger\u001B[38;5;241m.\u001B[39mwarning(\n\u001B[1;32m    277\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFast initialization is currently not supported for SpeechEncoderDecoderModel. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    278\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFalling back to slow initialization...\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    279\u001B[0m     )\n\u001B[1;32m    280\u001B[0m kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_fast_init\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m--> 281\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages/transformers/modeling_utils.py:3886\u001B[0m, in \u001B[0;36mPreTrainedModel.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m   3880\u001B[0m config \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_autoset_attn_implementation(\n\u001B[1;32m   3881\u001B[0m     config, use_flash_attention_2\u001B[38;5;241m=\u001B[39muse_flash_attention_2, torch_dtype\u001B[38;5;241m=\u001B[39mtorch_dtype, device_map\u001B[38;5;241m=\u001B[39mdevice_map\n\u001B[1;32m   3882\u001B[0m )\n\u001B[1;32m   3884\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ContextManagers(init_contexts):\n\u001B[1;32m   3885\u001B[0m     \u001B[38;5;66;03m# Let's make sure we don't run the init function of buffer modules\u001B[39;00m\n\u001B[0;32m-> 3886\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3888\u001B[0m \u001B[38;5;66;03m# make sure we use the model's config since the __init__ call might have copied it\u001B[39;00m\n\u001B[1;32m   3889\u001B[0m config \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mconfig\n",
      "File \u001B[0;32m~/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages/transformers/models/speech_encoder_decoder/modeling_speech_encoder_decoder.py:215\u001B[0m, in \u001B[0;36mSpeechEncoderDecoderModel.__init__\u001B[0;34m(self, config, encoder, decoder)\u001B[0m\n\u001B[1;32m    212\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(config)\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m encoder \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 215\u001B[0m     encoder \u001B[38;5;241m=\u001B[39m \u001B[43mAutoModel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_config\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattn_implementation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_attn_implementation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    217\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m decoder \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    218\u001B[0m     decoder \u001B[38;5;241m=\u001B[39m AutoModelForCausalLM\u001B[38;5;241m.\u001B[39mfrom_config(config\u001B[38;5;241m.\u001B[39mdecoder, attn_implementation\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39m_attn_implementation)\n",
      "File \u001B[0;32m~/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:439\u001B[0m, in \u001B[0;36m_BaseAutoModelClass.from_config\u001B[0;34m(cls, config, **kwargs)\u001B[0m\n\u001B[1;32m    437\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model_class\u001B[38;5;241m.\u001B[39m_from_config(config, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    438\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(config) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[0;32m--> 439\u001B[0m     model_class \u001B[38;5;241m=\u001B[39m \u001B[43m_get_model_class\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_model_mapping\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    440\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model_class\u001B[38;5;241m.\u001B[39m_from_config(config, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    442\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    443\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnrecognized configuration class \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m for this kind of AutoModel: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    444\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel type should be one of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(c\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mc\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping\u001B[38;5;241m.\u001B[39mkeys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    445\u001B[0m )\n",
      "File \u001B[0;32m~/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:388\u001B[0m, in \u001B[0;36m_get_model_class\u001B[0;34m(config, model_mapping)\u001B[0m\n\u001B[1;32m    387\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_model_class\u001B[39m(config, model_mapping):\n\u001B[0;32m--> 388\u001B[0m     supported_models \u001B[38;5;241m=\u001B[39m \u001B[43mmodel_mapping\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m    389\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(supported_models, (\u001B[38;5;28mlist\u001B[39m, \u001B[38;5;28mtuple\u001B[39m)):\n\u001B[1;32m    390\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m supported_models\n",
      "File \u001B[0;32m~/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:763\u001B[0m, in \u001B[0;36m_LazyAutoMapping.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m    761\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_type \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping:\n\u001B[1;32m    762\u001B[0m     model_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping[model_type]\n\u001B[0;32m--> 763\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_attr_from_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    765\u001B[0m \u001B[38;5;66;03m# Maybe there was several model types associated with this config.\u001B[39;00m\n\u001B[1;32m    766\u001B[0m model_types \u001B[38;5;241m=\u001B[39m [k \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_config_mapping\u001B[38;5;241m.\u001B[39mitems() \u001B[38;5;28;01mif\u001B[39;00m v \u001B[38;5;241m==\u001B[39m key\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m]\n",
      "File \u001B[0;32m~/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:777\u001B[0m, in \u001B[0;36m_LazyAutoMapping._load_attr_from_module\u001B[0;34m(self, model_type, attr)\u001B[0m\n\u001B[1;32m    775\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m module_name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_modules:\n\u001B[1;32m    776\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_modules[module_name] \u001B[38;5;241m=\u001B[39m importlib\u001B[38;5;241m.\u001B[39mimport_module(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodule_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtransformers.models\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 777\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgetattribute_from_module\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_modules\u001B[49m\u001B[43m[\u001B[49m\u001B[43mmodule_name\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattr\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:693\u001B[0m, in \u001B[0;36mgetattribute_from_module\u001B[0;34m(module, attr)\u001B[0m\n\u001B[1;32m    691\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(attr, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m    692\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mtuple\u001B[39m(getattribute_from_module(module, a) \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m attr)\n\u001B[0;32m--> 693\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mhasattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mmodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattr\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m    694\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(module, attr)\n\u001B[1;32m    695\u001B[0m \u001B[38;5;66;03m# Some of the mappings have entries model_type -> object of another model type. In that case we try to grab the\u001B[39;00m\n\u001B[1;32m    696\u001B[0m \u001B[38;5;66;03m# object at the top level.\u001B[39;00m\n",
      "File \u001B[0;32m~/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages/transformers/utils/import_utils.py:1754\u001B[0m, in \u001B[0;36m_LazyModule.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1752\u001B[0m     value \u001B[38;5;241m=\u001B[39m Placeholder\n\u001B[1;32m   1753\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_class_to_module\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[0;32m-> 1754\u001B[0m     module \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_module\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_class_to_module\u001B[49m\u001B[43m[\u001B[49m\u001B[43mname\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1755\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(module, name)\n\u001B[1;32m   1756\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages/transformers/utils/import_utils.py:1766\u001B[0m, in \u001B[0;36m_LazyModule._get_module\u001B[0;34m(self, module_name)\u001B[0m\n\u001B[1;32m   1764\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m importlib\u001B[38;5;241m.\u001B[39mimport_module(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m module_name, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n\u001B[1;32m   1765\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m-> 1766\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m   1767\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to import \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodule_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m because of the following error (look up to see its\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1768\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m traceback):\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1769\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Failed to import transformers.models.wav2vec2.modeling_wav2vec2 because of the following error (look up to see its traceback):\n/home/daoan/Projects/AI_Challenge_HCMC_2024/.venv/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops5zeros4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEE"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T17:23:00.101948Z",
     "start_time": "2024-08-13T17:23:00.099509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def decode_tokens(token_ids, skip_special_tokens=True):\n",
    "    outputs = [[]]\n",
    "    for token in token_ids:\n",
    "        if token < tokenizer.vocab_size:  # Bỏ qua các token timestamp\n",
    "            outputs[-1].append(token)\n",
    "    outputs = [\n",
    "         tokenizer.decode(s, skip_special_tokens=skip_special_tokens) for s in outputs\n",
    "    ]\n",
    "\n",
    "    return \"\".join(outputs).replace(\"<\",\"\").replace(\">\",\"\")"
   ],
   "id": "f389855700833496",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def speech_to_text(audio_path):\n",
    "    waveform, sample_rate = torchaudio.load(audio_path)\n",
    "    input_values = feature_extractor(waveform, sampling_rate=sample_rate, return_tensors=\"pt\").input_values.to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values).logits\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    transcription = decode_tokens(predicted_ids[0])\n",
    "    return transcription"
   ],
   "id": "8005a46178641b7a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
