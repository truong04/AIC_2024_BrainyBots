{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install git+https://github.com/xinyu1205/recognize-anything.git\n",
   "id": "9df4970e2a5afe69"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T19:03:29.056763Z",
     "start_time": "2024-10-12T19:03:29.046636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "def download_checkpoints(model):\n",
    "    print('You selected', model)\n",
    "    if not os.path.exists('pretrained'):\n",
    "        os.makedirs('pretrained')\n",
    "\n",
    "    if model == \"RAM\":\n",
    "        ram_weights_path = 'pretrained/ram_swin_large_14m.pth'\n",
    "        if not os.path.exists(ram_weights_path):\n",
    "            !wget https://huggingface.co/spaces/xinyu1205/Recognize_Anything-Tag2Text/resolve/main/ram_swin_large_14m.pth -O pretrained/ram_swin_large_14m.pth\n",
    "        else:\n",
    "            print(\"RAM weights already downloaded!\")\n",
    "    if model == \"RAM+\":\n",
    "        ram_plus_weights_path = 'pretrained/ram_plus_swin_large_14m.pth'\n",
    "        if not os.path.exists(ram_plus_weights_path):\n",
    "            !wget https://huggingface.co/xinyu1205/recognize-anything-plus-model/resolve/main/ram_plus_swin_large_14m.pth -O pretrained/ram_plus_swin_large_14m.pth\n",
    "        else:\n",
    "            print(\"RAM+ weights already downloaded!\")\n",
    "    if model == \"Tag2Text\":\n",
    "        tag2text_weights_path = 'pretrained/tag2text_swin_14m.pth'\n",
    "        if not os.path.exists(tag2text_weights_path):\n",
    "            !wget https://huggingface.co/spaces/xinyu1205/Recognize_Anything-Tag2Text/resolve/main/tag2text_swin_14m.pth -O pretrained/tag2text_swin_14m.pth\n",
    "        else:\n",
    "            print(\"Tag2Text weights already downloaded!\")\n",
    "\n",
    "\n",
    "model = \"RAM\"\n",
    "download_checkpoints(model)\n",
    "print(model, 'weights are downloaded!')\n",
    "\n",
    "model = \"RAM+\"\n",
    "download_checkpoints(model)\n",
    "print(model, 'weights are downloaded!')\n",
    "\n",
    "model = \"Tag2Text\"\n",
    "download_checkpoints(model)\n",
    "print(model, 'weights are downloaded!')"
   ],
   "id": "474703bf15258dc4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You selected RAM\n",
      "RAM weights already downloaded!\n",
      "RAM weights are downloaded!\n",
      "You selected RAM+\n",
      "RAM+ weights already downloaded!\n",
      "RAM+ weights are downloaded!\n",
      "You selected Tag2Text\n",
      "Tag2Text weights already downloaded!\n",
      "Tag2Text weights are downloaded!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T19:03:30.455887Z",
     "start_time": "2024-10-12T19:03:30.453618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "def find_all_keyframe_files(root_dir, extensions=[\".jpg\"]):\n",
    "    files = []\n",
    "    for dirpath, _, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            if any(filename.lower().endswith(ext) for ext in extensions):\n",
    "                files.append(os.path.join(dirpath, filename))\n",
    "    return files"
   ],
   "id": "ab7337b361095416",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T19:03:31.304370Z",
     "start_time": "2024-10-12T19:03:31.301427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "def get_video_id_and_frame_id(file_path):\n",
    "    pattern = r\"/([A-Z0-9]+)_extra/([A-Z0-9]+)/(\\d+)\\.*\"\n",
    "    match = re.search(pattern, file_path)\n",
    "    if match:\n",
    "        video_id = f\"{match.group(1)}_{match.group(2)}\"\n",
    "        frame_id = match.group(3)\n",
    "        return video_id, frame_id\n",
    "    else:\n",
    "        print(\"No match found: \" + file_path)\n",
    "        return None, None"
   ],
   "id": "57e8d19132f73e42",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T19:03:33.862969Z",
     "start_time": "2024-10-12T19:03:31.747607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ram.models import ram_plus, ram\n",
    "import torch\n",
    "from ram import get_transform\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def load_ram_model():\n",
    "    model = ram(pretrained='pretrained/ram_swin_large_14m.pth',\n",
    "                     image_size=384,\n",
    "                     vit='swin_l')\n",
    "    return model.to(device).eval()\n",
    "\n",
    "def load_ram_plus_model():\n",
    "    model = ram_plus(pretrained='pretrained/ram_plus_swin_large_14m.pth',\n",
    "                 image_size=384,\n",
    "                 vit='swin_l')\n",
    "    return model.to(device).eval()\n",
    "\n",
    "transform = get_transform(image_size=384)\n"
   ],
   "id": "eda22e46adb29aa7",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T19:03:47.619827Z",
     "start_time": "2024-10-12T19:03:33.869007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "from ram import inference_ram as inference\n",
    "\n",
    "ram_model = load_ram_model()\n",
    "ram_plus_model = load_ram_plus_model()\n",
    "space_pattern = re.compile('^[\\S]+')\n",
    "\n",
    "def inference_ram(image_path):\n",
    "   image = transform(Image.open(image_path)).unsqueeze(0).to(device)\n",
    "   ram_res = inference(image, ram_model)[0].split(\" | \")\n",
    "   ram_plus_res = inference(image, ram_plus_model)[0].split(\" | \")\n",
    "   result = list(set(ram_res + ram_plus_res))\n",
    "   result = list(filter(space_pattern.match,result))\n",
    "   return result"
   ],
   "id": "feb8d0d05eba9678",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertLMHeadModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/encoder/layer/0/crossattention/self/query is tied\n",
      "/encoder/layer/0/crossattention/self/key is tied\n",
      "/encoder/layer/0/crossattention/self/value is tied\n",
      "/encoder/layer/0/crossattention/output/dense is tied\n",
      "/encoder/layer/0/crossattention/output/LayerNorm is tied\n",
      "/encoder/layer/0/intermediate/dense is tied\n",
      "/encoder/layer/0/output/dense is tied\n",
      "/encoder/layer/0/output/LayerNorm is tied\n",
      "/encoder/layer/1/crossattention/self/query is tied\n",
      "/encoder/layer/1/crossattention/self/key is tied\n",
      "/encoder/layer/1/crossattention/self/value is tied\n",
      "/encoder/layer/1/crossattention/output/dense is tied\n",
      "/encoder/layer/1/crossattention/output/LayerNorm is tied\n",
      "/encoder/layer/1/intermediate/dense is tied\n",
      "/encoder/layer/1/output/dense is tied\n",
      "/encoder/layer/1/output/LayerNorm is tied\n",
      "--------------\n",
      "pretrained/ram_swin_large_14m.pth\n",
      "--------------\n",
      "load checkpoint from pretrained/ram_swin_large_14m.pth\n",
      "vit: swin_l\n",
      "--------------\n",
      "pretrained/ram_plus_swin_large_14m.pth\n",
      "--------------\n",
      "load checkpoint from pretrained/ram_plus_swin_large_14m.pth\n",
      "vit: swin_l\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T22:38:09.757198Z",
     "start_time": "2024-10-12T19:03:47.630008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "from ram import inference_ram as inference\n",
    "\n",
    "keyframe_dir = \"/media/daoan/T7 Shield2/AI_Challenge_2024_DATA/Keyframes\"\n",
    "tag_dir = keyframe_dir.replace(\"Keyframes\", \"Tags\")\n",
    "keyframe_paths = find_all_keyframe_files(keyframe_dir)\n",
    "keywords = [\"L25_extra\", \"L26_extra\", \"L27_extra\", \"L28_extra\", \"L29_extra\", \"L30_extra\"]\n",
    "filtered_keyframe_paths = [path for path in keyframe_paths if any(keyword in path for keyword in keywords)]\n",
    "\n",
    "for keyframe_path in tqdm(filtered_keyframe_paths, \"Inference\"):\n",
    "    video_id, frame_id = get_video_id_and_frame_id(keyframe_path)\n",
    "    folder_id = video_id.split(\"_\")[0]\n",
    "    video_id = video_id.split(\"_\")[1]\n",
    "    tag_path = os.path.join(tag_dir, folder_id + \"_extra\", video_id, f\"{frame_id}.txt\")\n",
    "    # create folder if not exists\n",
    "    if not os.path.exists(os.path.dirname(tag_path)):\n",
    "        os.makedirs(os.path.dirname(tag_path))\n",
    "    if not os.path.exists(tag_path):\n",
    "        tags = inference_ram(keyframe_path)\n",
    "        with open(tag_path, \"w\", encoding='utf-8') as f:\n",
    "            f.write(\" | \".join(tags))\n"
   ],
   "id": "5430a76c2cb4767",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 305552/305552 [3:34:15<00:00, 23.77it/s]  \n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f4d58cfba67d8f40"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
