{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T02:06:37.521556Z",
     "start_time": "2024-09-20T02:06:34.650257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import transformers\n",
    "import time\n",
    "import requests\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from skimage.io import imread\n",
    "from transformers import AutoProcessor, AutoModelForZeroShotObjectDetection\n",
    "print(transformers.__version__)\n",
    "model_id = \"IDEA-Research/grounding-dino-base\"\n",
    "device = \"cuda\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "model = AutoModelForZeroShotObjectDetection.from_pretrained(model_id).to(device)"
   ],
   "id": "6c306f424763bec2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.44.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not load the custom kernel for multi-scale deformable attention: /home/daoan/.cache/torch_extensions/py310_cu118/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory\n",
      "Could not load the custom kernel for multi-scale deformable attention: /home/daoan/.cache/torch_extensions/py310_cu118/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory\n",
      "Could not load the custom kernel for multi-scale deformable attention: /home/daoan/.cache/torch_extensions/py310_cu118/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory\n",
      "Could not load the custom kernel for multi-scale deformable attention: /home/daoan/.cache/torch_extensions/py310_cu118/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory\n",
      "Could not load the custom kernel for multi-scale deformable attention: /home/daoan/.cache/torch_extensions/py310_cu118/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory\n",
      "Could not load the custom kernel for multi-scale deformable attention: /home/daoan/.cache/torch_extensions/py310_cu118/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory\n",
      "Could not load the custom kernel for multi-scale deformable attention: /home/daoan/.cache/torch_extensions/py310_cu118/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory\n",
      "Could not load the custom kernel for multi-scale deformable attention: /home/daoan/.cache/torch_extensions/py310_cu118/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory\n",
      "Could not load the custom kernel for multi-scale deformable attention: /home/daoan/.cache/torch_extensions/py310_cu118/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory\n",
      "Could not load the custom kernel for multi-scale deformable attention: /home/daoan/.cache/torch_extensions/py310_cu118/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory\n",
      "Could not load the custom kernel for multi-scale deformable attention: /home/daoan/.cache/torch_extensions/py310_cu118/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory\n",
      "Could not load the custom kernel for multi-scale deformable attention: /home/daoan/.cache/torch_extensions/py310_cu118/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T15:01:59.807177Z",
     "start_time": "2024-08-28T15:01:59.804506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "def find_all_keyframe_files(root_dir, extensions=[\".jpg\"]):\n",
    "    files = []\n",
    "    for dirpath, _, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            if any(filename.lower().endswith(ext) for ext in extensions):\n",
    "                files.append(os.path.join(dirpath, filename))\n",
    "    return files"
   ],
   "id": "c38e2e47c225beed",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T15:02:02.381376Z",
     "start_time": "2024-08-28T15:02:02.378151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_video_id_and_frame_id(file_path):\n",
    "    pattern = r\"/([A-Z0-9]+)_extra/([A-Z0-9]+)/(\\d+)\\.*\"\n",
    "    match = re.search(pattern, file_path)\n",
    "    if match:\n",
    "        video_id = f\"{match.group(1)}_{match.group(2)}\"\n",
    "        frame_id = match.group(3)\n",
    "        return video_id, frame_id\n",
    "    else:\n",
    "        print(\"No match found: \" + file_path)\n",
    "        return None, None"
   ],
   "id": "dc3e58beddac7332",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T15:08:24.065478Z",
     "start_time": "2024-08-28T15:08:24.062888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_tags_from_keyframe_file(file_path):\n",
    "    with open(file_path.replace(\"Keyframes\", \"Tags\").replace(\"jpg\", \"txt\"), \"r\") as file:\n",
    "        return file.read().replace(\"|\", \".\").strip() + \" . \""
   ],
   "id": "24d506d8096ea036",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:36:28.330339Z",
     "start_time": "2024-08-31T14:36:28.324492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_od_from_keyframe_file(file_path):\n",
    "    od_path = file_path.replace(\"Keyframes\", \"object_detection\").replace(\"jpg\", \"txt\")\n",
    "        # create folder if not exists\n",
    "    if not os.path.exists(os.path.dirname(od_path)):\n",
    "        os.makedirs(os.path.dirname(od_path))\n",
    "    return od_path"
   ],
   "id": "b3ab7da2b9df7576",
   "outputs": [],
   "execution_count": 393
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T14:21:24.374966Z",
     "start_time": "2024-08-29T14:21:24.369872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_list_into_chunks(lst, chunk_size):\n",
    "    return [lst[i:i + chunk_size] for i in range(0, len(lst), chunk_size)]"
   ],
   "id": "2e8887b7baa48112",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T15:27:08.841295Z",
     "start_time": "2024-08-28T15:27:07.296045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "key_frame_paths = find_all_keyframe_files(\"/media/daoan/T7 Shield2/VN_Multi_User_Video_Search/Keyframes\")\n",
    "keywords = [\"L16_extra\", \"L17_extra\", \"L18_extra\", \"L19_extra\", \"L20_extra\", \"L21_extra\"]\n",
    "key_frame_paths = [path for path in key_frame_paths if any(keyword in path for keyword in keywords)]\n",
    "len(key_frame_paths)"
   ],
   "id": "1fc536dc3eba23d6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1383856\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T20:09:13.673131Z",
     "start_time": "2024-08-31T14:36:32.151159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 4\n",
    "\n",
    "# List of image paths\n",
    "chucks = split_list_into_chunks(key_frame_paths, batch_size)\n",
    "\n",
    "for chuck in tqdm(chucks, \"Processing batches\"):\n",
    "# Load and preprocess images in batches\n",
    "    batch_images = []\n",
    "    for image_path in chuck:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        batch_images.append(image)\n",
    "    texts = []\n",
    "    for image_path in chuck:\n",
    "        texts.append(get_tags_from_keyframe_file(image_path))\n",
    "\n",
    "    inputs = processor(images=batch_images, text=texts, return_tensors=\"pt\",\n",
    "                       padding=True,\n",
    "                       truncation=True\n",
    "                       ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Post-process the results for each batch\n",
    "    results = processor.post_process_grounded_object_detection(\n",
    "        outputs,\n",
    "        inputs.input_ids,\n",
    "        box_threshold=0.4,\n",
    "        text_threshold=0.3,\n",
    "        target_sizes=[image.size[::-1] for image in batch_images]\n",
    "    )\n",
    "    \n",
    "    for index, result in enumerate(results):\n",
    "        scores = result['scores']\n",
    "        labels = result['labels']\n",
    "        boxes = result['boxes']\n",
    "        data = []\n",
    "        for score, label, box in zip(scores, labels, boxes):\n",
    "            box = box.tolist()\n",
    "            data.append(f\"{label} | {score:.2f} | {box[0]} {box[1]} {box[2]} {box[3]}\")       \n",
    "        with open(get_od_from_keyframe_file(chuck[index]), \"w\", encoding='utf-8') as file:\n",
    "            file.write(\"\\n\".join(data))"
   ],
   "id": "ba4061122095419f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 345964/345964 [53:32:41<00:00,  1.79it/s]   \n"
     ]
    }
   ],
   "execution_count": 394
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
